{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-11T12:53:35.622645Z",
     "iopub.status.busy": "2026-01-11T12:53:35.622077Z",
     "iopub.status.idle": "2026-01-11T12:53:40.577608Z",
     "shell.execute_reply": "2026-01-11T12:53:40.576719Z",
     "shell.execute_reply.started": "2026-01-11T12:53:35.622628Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ijson\n",
      "  Downloading ijson-3.4.0.post0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "Downloading ijson-3.4.0.post0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (134 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ijson\n",
      "Successfully installed ijson-3.4.0.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:10:23.569945Z",
     "iopub.status.busy": "2026-01-11T14:10:23.569639Z",
     "iopub.status.idle": "2026-01-11T14:10:23.575615Z",
     "shell.execute_reply": "2026-01-11T14:10:23.574922Z",
     "shell.execute_reply.started": "2026-01-11T14:10:23.569929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import ijson\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything from utility_scripts\n",
    "from utility_scripts.tree import tree\n",
    "from utility_scripts.taxonomy import parse_taxonomy\n",
    "from utility_scripts.mapping import build_taxa_maps\n",
    "from utility_scripts.corruption_scan import verify_image_validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T12:52:54.378118Z",
     "iopub.status.busy": "2026-01-11T12:52:54.377843Z",
     "iopub.status.idle": "2026-01-11T12:52:54.383610Z",
     "shell.execute_reply": "2026-01-11T12:52:54.382186Z",
     "shell.execute_reply.started": "2026-01-11T12:52:54.378105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Input files\n",
    "base_folder = \"/kaggle/input/inaturalist-insects/\"\n",
    "\n",
    "public_test_folder = os.path.join(base_folder, \"public_test/public_test\")\n",
    "train_folder = os.path.join(base_folder, \"train/train\")\n",
    "train_mini_folder = os.path.join(base_folder, \"train_mini/train_mini\")\n",
    "val_folder = os.path.join(base_folder, \"val/val\")\n",
    "\n",
    "public_test_json = os.path.join(base_folder, \"public_test-json/public_test.json\")\n",
    "train_json = os.path.join(base_folder, \"train-json/train.json\")\n",
    "train_mini_json = os.path.join(base_folder, \"train_mini-json/train_mini.json\")\n",
    "val_json = os.path.join(base_folder, \"val-json/val.json\")\n",
    "\n",
    "# Output files\n",
    "working_dir = \"/kaggle/working/\"\n",
    "\n",
    "tree_file = os.path.join(working_dir, \"tree.txt\")\n",
    "hierarchy_map_file = \"/kaggle/working/hierarchy_map.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-11T09:20:26.873617Z",
     "iopub.status.busy": "2026-01-11T09:20:26.873290Z",
     "iopub.status.idle": "2026-01-11T09:20:26.936737Z",
     "shell.execute_reply": "2026-01-11T09:20:26.935802Z",
     "shell.execute_reply.started": "2026-01-11T09:20:26.873594Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÃ©sultat: {'ordre': 'Lepidoptera', 'famille': 'Erebidae', 'genre': 'Arctia', 'espece': 'virginalis'}\n",
      "Image valide\n"
     ]
    }
   ],
   "source": [
    "example = \"train/train/00980_Animalia_Arthropoda_Insecta_Lepidoptera_Erebidae_Arctia_virginalis/464f3a34-4c04-4eb3-afa2-6cb7444c3fa3.jpg\"\n",
    "taxonomy = parse_taxonomy(example)\n",
    "print(\"RÃ©sultat:\", taxonomy)\n",
    "validity = verify_image_validy(example)\n",
    "print(\"Image valide\" if validity else \"Image invalide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-11T09:20:29.374015Z",
     "iopub.status.busy": "2026-01-11T09:20:29.373687Z",
     "iopub.status.idle": "2026-01-11T09:56:28.751665Z",
     "shell.execute_reply": "2026-01-11T09:56:28.750620Z",
     "shell.execute_reply.started": "2026-01-11T09:20:29.373991Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre total de fichiers : 1315246\n"
     ]
    }
   ],
   "source": [
    "total = tree(base_folder, 2)\n",
    "print(f\"\\nNombre total de fichiers : {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:19:23.774461Z",
     "iopub.status.busy": "2026-01-11T11:19:23.774184Z",
     "iopub.status.idle": "2026-01-11T11:19:23.779579Z",
     "shell.execute_reply": "2026-01-11T11:19:23.778726Z",
     "shell.execute_reply.started": "2026-01-11T11:19:23.774440Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_annotated_images(json_path):\n",
    "    \"\"\"Charge lat/lon par file_name depuis train_mini_json.\"\"\"\n",
    "    annotated = {}\n",
    "    with open(json_path, 'rb') as f:\n",
    "        parser = ijson.items(f, 'images.item')\n",
    "        for img in parser:\n",
    "            filename = img.get('file_name', '')\n",
    "            lat = float(img.get('latitude')) if img.get('latitude') is not None else 0.0\n",
    "            lon = float(img.get('longitude')) if img.get('longitude') is not None else 0.0\n",
    "            annotated[filename] = (lat, lon)\n",
    "    return annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:19:31.985291Z",
     "iopub.status.busy": "2026-01-11T11:19:31.984870Z",
     "iopub.status.idle": "2026-01-11T11:19:31.993632Z",
     "shell.execute_reply": "2026-01-11T11:19:31.992596Z",
     "shell.execute_reply.started": "2026-01-11T11:19:31.985261Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_stats(full_taxa_map, full_geo_db, species_encountered):\n",
    "    \"\"\"Calcule toutes stats.\"\"\"\n",
    "    ordre_count = Counter()\n",
    "    famille_count = Counter()\n",
    "    genre_count = Counter()\n",
    "    espece_count = Counter()\n",
    "    \n",
    "    for taxon_key, hier in full_taxa_map.items():\n",
    "        ordre_count[hier['ordre']] += 1\n",
    "        famille_count[hier['famille']] += 1\n",
    "        genre_count[hier['genre']] += 1\n",
    "        espece_count[hier['espece']] += 1\n",
    "    \n",
    "    homonyms_count = len([s for s in species_encountered if len(species_encountered[s]) > 1])\n",
    "    homonyms_dirs = sum(len(species_encountered[s]) for s in species_encountered if len(species_encountered[s]) > 1)\n",
    "    \n",
    "    taxon_geo_counts = {str(k): len(v) for k, v in full_geo_db.items()}\n",
    "    geo_taxa = len(full_geo_db)\n",
    "    total_taxa = len(full_taxa_map)\n",
    "    multi_geo = sum(1 for c in taxon_geo_counts.values() if c > 1)\n",
    "    \n",
    "    return {\n",
    "        'total_dirs': len(species_encountered),\n",
    "        'unique_taxa': total_taxa,\n",
    "        'geo_coverage': geo_taxa / total_taxa if total_taxa else 0,\n",
    "        'homonyms': {'names': homonyms_count, 'dirs': homonyms_dirs},\n",
    "        'hierarchy': {\n",
    "            'ordres': len(ordre_count), 'familles': len(famille_count), 'genres': len(genre_count)\n",
    "        },\n",
    "        'taxon_geo_counts': taxon_geo_counts\n",
    "    }, ordre_count, famille_count, genre_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-11T11:31:04.266165Z",
     "iopub.status.busy": "2026-01-11T11:31:04.265370Z",
     "iopub.status.idle": "2026-01-11T11:31:10.026437Z",
     "shell.execute_reply": "2026-01-11T11:31:10.025528Z",
     "shell.execute_reply.started": "2026-01-11T11:31:04.266136Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 2526 taxons (sur 2252 dossiers)\n",
      "Homonymes: 185 noms â†’ 459 dossiers\n",
      "HiÃ©rarchie: 17 ordres, 190 fam., 1472 genres\n",
      "GÃ©o: 2526/2526 (100.0%)\n",
      "Non parsÃ©s: 0\n",
      "ðŸ’¾ SauvegardÃ©: 2526 taxons dans /kaggle/working/hierarchy_map.json\n"
     ]
    }
   ],
   "source": [
    "annotated_images = load_annotated_images(train_mini_json)\n",
    "species_encountered, unparsed_dirs = parse_taxonomy_folders(train_mini_folder)\n",
    "full_taxa_map, full_geo_db = build_taxa_maps(species_encountered, annotated_images, train_mini_folder)\n",
    "stats, ordre_count, famille_count, genre_count = compute_stats(full_taxa_map, full_geo_db, species_encountered)\n",
    "\n",
    "print(f\"âœ… {stats['unique_taxa']} taxons (sur {stats['total_dirs']} dossiers)\")\n",
    "print(f\"Homonymes: {stats['homonyms']['names']} noms â†’ {stats['homonyms']['dirs']} dossiers\")\n",
    "print(f\"HiÃ©rarchie: {stats['hierarchy']['ordres']} ordres, {stats['hierarchy']['familles']} familles, {stats['hierarchy']['genres']} genres\")\n",
    "print(f\"GÃ©o: {len(full_geo_db)}/{len(full_taxa_map)} ({stats['geo_coverage']*100:.1f}%)\")\n",
    "print(f\"Non parsÃ©s: {len(unparsed_dirs)}\")\n",
    "\n",
    "save_hierarchy_map(full_taxa_map, full_geo_db, stats, hierarchy_map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:29:14.223558Z",
     "iopub.status.busy": "2026-01-11T14:29:14.223257Z",
     "iopub.status.idle": "2026-01-11T14:29:14.233873Z",
     "shell.execute_reply": "2026-01-11T14:29:14.232695Z",
     "shell.execute_reply.started": "2026-01-11T14:29:14.223536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RobustImageFolder(Dataset):\n",
    "    \"\"\"ImageFolder skip corrompus.\"\"\"\n",
    "    def __init__(self, root, transform=None, corrupt_files=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.corrupt_files = set(corrupt_files or [])\n",
    "        \n",
    "        self.classes, self.class_to_idx = self.find_classes(self.root)\n",
    "        self.samples = self.make_dataset(self.root, self.class_to_idx)\n",
    "        \n",
    "        self.valid_indices = []\n",
    "        for i, (path, _) in enumerate(self.samples):\n",
    "            if os.path.relpath(path, self.root) not in self.corrupt_files:\n",
    "                self.valid_indices.append(i)\n",
    "    \n",
    "    def find_classes(self, directory):\n",
    "        \"\"\"Trouve classes (dossiers).\"\"\"\n",
    "        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "    \n",
    "    def make_dataset(self, directory, class_to_idx):\n",
    "        \"\"\"Construit samples comme ImageFolder.\"\"\"\n",
    "        samples = []\n",
    "        for target_class in sorted(self.class_to_idx.keys()):\n",
    "            class_index = self.class_to_idx[target_class]\n",
    "            target_dir = os.path.join(directory, target_class)\n",
    "            for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n",
    "                for fname in sorted(fnames):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    item = (path, class_index)\n",
    "                    samples.append(item)\n",
    "        return samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[self.valid_indices[index]]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:10:31.060279Z",
     "iopub.status.busy": "2026-01-11T14:10:31.060006Z",
     "iopub.status.idle": "2026-01-11T14:19:58.673901Z",
     "shell.execute_reply": "2026-01-11T14:19:58.672672Z",
     "shell.execute_reply.started": "2026-01-11T14:10:31.060263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan 126300 JPG dans /kaggle/input/inaturalist-insects/train_mini/train_mini\n",
      "âŒ 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: OSError: image file is truncated (115 bytes not processed)\n",
      "âŒ 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural\n",
      "âŒ 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural\n",
      "âŒ 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: OSError: image file is truncated (43 bytes not processed)\n",
      "âŒ 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: OSError: image file is truncated (124 bytes not processed)\n",
      "âŒ 00620_Animalia_Arthropoda_Insecta_Hemiptera_Pentat: UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural\n",
      "âŒ 00620_Animalia_Arthropoda_Insecta_Hemiptera_Pentat: OSError: image file is truncated (62 bytes not processed)\n",
      "âŒ 00620_Animalia_Arthropoda_Insecta_Hemiptera_Pentat: OSError: image file is truncated (67 bytes not processed)\n",
      "âŒ 00620_Animalia_Arthropoda_Insecta_Hemiptera_Pentat: OSError: image file is truncated (88 bytes not processed)\n",
      "\n",
      "TYPES D'ERREURS:\n",
      "  UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural: 45\n",
      "  OSError: image file is truncated (115 bytes not processed): 1\n",
      "  OSError: image file is truncated (43 bytes not processed): 1\n",
      "  OSError: image file is truncated (124 bytes not processed): 1\n",
      "  OSError: image file is truncated (62 bytes not processed): 1\n",
      "  OSError: image file is truncated (67 bytes not processed): 1\n",
      "  OSError: image file is truncated (88 bytes not processed): 1\n",
      "  OSError: image file is truncated (23 bytes not processed): 1\n",
      "  OSError: image file is truncated (26 bytes not processed): 1\n",
      "  OSError: image file is truncated (83 bytes not processed): 1\n",
      "  OSError: image file is truncated (106 bytes not processed): 1\n",
      "âœ… 55/126300 (0.0%) en 506.9s\n",
      "Scan 25260 JPG dans /kaggle/input/inaturalist-insects/val/val\n",
      "\n",
      "TYPES D'ERREURS:\n",
      "âœ… 0/25260 (0.0%) en 60.6s\n",
      "\n",
      "CORROMPUS TRAIN:\n",
      " # Corrompus: 55/126300 (0.0%)\n",
      "# Erreurs:\n",
      "# OSError: image file is truncated (115 bytes not processed): 1\n",
      "# UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural: 45\n",
      "# OSError: image file is truncated (43 bytes not processed): 1\n",
      "# OSError: image file is truncated (124 bytes not processed): 1\n",
      "# OSError: image file is truncated (62 bytes not processed): 1\n",
      "# OSError: image file is truncated (67 bytes not processed): 1\n",
      "# OSError: image file is truncated (88 bytes not processed): ...\n"
     ]
    }
   ],
   "source": [
    "corrupted_train, train_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/train_mini/train_mini', max_workers=4)\n",
    "corrupted_val, val_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/val/val', max_workers=4)\n",
    "\n",
    "with open(train_log) as f:\n",
    "    print(\"\\nCORROMPUS TRAIN:\\n\", f.read()[:500] + \"...\" if os.path.getsize(train_log) > 500 else f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:29:21.524378Z",
     "iopub.status.busy": "2026-01-11T14:29:21.524063Z",
     "iopub.status.idle": "2026-01-11T14:29:21.534947Z",
     "shell.execute_reply": "2026-01-11T14:29:21.534373Z",
     "shell.execute_reply.started": "2026-01-11T14:29:21.524359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "corrupt_train = []\n",
    "with open('/kaggle/working/corrupted_train_mini.txt') as f:\n",
    "    for line in f:\n",
    "        if line.strip() and not line.startswith('#'):\n",
    "            corrupt_train.append(line.strip())\n",
    "\n",
    "corrupt_val = []\n",
    "with open('/kaggle/working/corrupted_val.txt') as f:\n",
    "    for line in f:\n",
    "        if line.strip() and not line.startswith('#'):\n",
    "            corrupt_val.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:29:24.768465Z",
     "iopub.status.busy": "2026-01-11T14:29:24.768169Z",
     "iopub.status.idle": "2026-01-11T14:30:36.718824Z",
     "shell.execute_reply": "2026-01-11T14:30:36.717720Z",
     "shell.execute_reply.started": "2026-01-11T14:29:24.768449Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 126300 â†’ 126245\n",
      "Val: 25260 â†’ 25260\n",
      "Classes: 2526\n"
     ]
    }
   ],
   "source": [
    "# Datasets FULL (sans skip)\n",
    "train_dataset_full = RobustImageFolder(train_mini_folder)\n",
    "val_dataset_full = RobustImageFolder(val_folder)\n",
    "\n",
    "# Datasets CLEAN\n",
    "train_dataset = RobustImageFolder(train_mini_folder, train_transforms, corrupt_train)\n",
    "val_dataset = RobustImageFolder(val_folder, val_transforms, corrupt_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'Train: {len(train_dataset_full)} â†’ {len(train_dataset)}')\n",
    "print(f'Val: {len(val_dataset_full)} â†’ {len(val_dataset)}')\n",
    "print(f'Classes: {len(train_dataset.classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:32:18.908926Z",
     "iopub.status.busy": "2026-01-11T14:32:18.908611Z",
     "iopub.status.idle": "2026-01-11T14:32:26.633926Z",
     "shell.execute_reply": "2026-01-11T14:32:26.632914Z",
     "shell.execute_reply.started": "2026-01-11T14:32:18.908908Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset /kaggle/input/inaturalist-insects/train_mini/train_mini: 126300 â†’ 126245 valides\n",
      "Dataset /kaggle/input/inaturalist-insects/val/val: 25260 â†’ 25260 valides\n",
      "âœ… Datasets hiÃ©rarchiques:\n",
      "  Train: 126245 images, 2526 classes\n",
      "  Val: 25260 images\n",
      "  Labels: ordre/famille/genre/espece [device=cpu]\n",
      "Batch shape: torch.Size([32, 3, 224, 224]), labels shape: torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class HierarchicalInsectDataset(Dataset):\n",
    "    def __init__(self, root_dir, hierarchy_map, transform=None, corrupt_files=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.hierarchy_map = hierarchy_map\n",
    "        self.transform = transform\n",
    "        \n",
    "        # ImageFolder interne\n",
    "        self.inner_dataset = datasets.ImageFolder(root_dir)\n",
    "        \n",
    "        # Filtre corrompus + hiÃ©rarchie\n",
    "        self.valid_indices = []\n",
    "        for i in range(len(self.inner_dataset)):\n",
    "            class_idx = self.inner_dataset.targets[i]\n",
    "            if class_idx in self.hierarchy_map:\n",
    "                # Skip si basename dans corrupt_files\n",
    "                path = self.inner_dataset.samples[i][0]\n",
    "                if os.path.basename(path) not in (corrupt_files or []):\n",
    "                    self.valid_indices.append(i)\n",
    "        \n",
    "        print(f\"Dataset {root_dir}: {len(self.inner_dataset)} â†’ {len(self.valid_indices)} valides\")\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.valid_indices[idx]\n",
    "        img, class_idx = self.inner_dataset[real_idx]\n",
    "        \n",
    "        # Labels hiÃ©rarchiques [ordre_id, famille_id, genre_id, espece_id]\n",
    "        hier_labels = torch.tensor(self.hierarchy_map[class_idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, hier_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "# === USAGE ===\n",
    "data_dir = '/kaggle/input/inaturalist-insects/'\n",
    "train_mini_folder = os.path.join(data_dir, 'train_mini/train_mini')\n",
    "val_folder = os.path.join(data_dir, 'val/val')\n",
    "\n",
    "# Datasets hiÃ©rarchiques\n",
    "train_dataset = HierarchicalInsectDataset(\n",
    "    train_mini_folder, \n",
    "    final_hierarchy, \n",
    "    transform=train_transforms,\n",
    "    corrupt_files=[os.path.basename(p) for p in corrupt_train]  # Seulement basenames\n",
    ")\n",
    "\n",
    "val_dataset = HierarchicalInsectDataset(\n",
    "    val_folder, \n",
    "    final_hierarchy, \n",
    "    transform=val_transforms,\n",
    "    corrupt_files=[os.path.basename(p) for p in corrupt_val]\n",
    ")\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… Datasets hiÃ©rarchiques:\")\n",
    "print(f\"  Train: {len(train_dataset)} images, 2526 classes\")\n",
    "print(f\"  Val: {len(val_dataset)} images\")\n",
    "print(f\"  Labels: ordre/famille/genre/espece [device={device}]\")\n",
    "\n",
    "# Test 1 batch\n",
    "img, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {img.shape}, labels shape: {labels.shape}\")  # [32,3,224,224], [32,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:39:06.995036Z",
     "iopub.status.busy": "2026-01-11T14:39:06.994708Z",
     "iopub.status.idle": "2026-01-11T14:39:08.934060Z",
     "shell.execute_reply": "2026-01-11T14:39:08.933051Z",
     "shell.execute_reply.started": "2026-01-11T14:39:06.995017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 5,622,173 params\n",
      "âœ… GPU: cpu\n",
      "âœ… Test OK: preds=torch.Size([32, 4, 2526]), loss=7.107\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import json\n",
    "\n",
    "class HierarchicalMobileNetV3(nn.Module):\n",
    "    \"\"\"MobileNetV3 avec outputs sÃ©parÃ©s par niveau.\"\"\"\n",
    "    def __init__(self, num_ordre=17, num_famille=190, num_genre=1472, num_espece=2526):\n",
    "        super().__init__()\n",
    "        backbone = models.mobilenet_v3_large(weights='IMAGENET1K_V1')\n",
    "        self.features = backbone.features\n",
    "        self.avgpool = backbone.avgpool\n",
    "        \n",
    "        self.fc_shared = nn.Sequential(\n",
    "            nn.Linear(960, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Heads indÃ©pendants (FIX: pas cumulatif)\n",
    "        self.head_ordre = nn.Linear(512, num_ordre)\n",
    "        self.head_famille = nn.Linear(512, num_famille)\n",
    "        self.head_genre = nn.Linear(512, num_genre)\n",
    "        self.head_espece = nn.Linear(512, num_espece)\n",
    "    \n",
    "    def forward(self, x, return_probs=False):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        feats = torch.flatten(x, 1)\n",
    "        shared = self.fc_shared(feats)\n",
    "        \n",
    "        ordre = self.head_ordre(shared)\n",
    "        famille = self.head_famille(shared)\n",
    "        genre = self.head_genre(shared)\n",
    "        espece = self.head_espece(shared)\n",
    "        \n",
    "        if return_probs:\n",
    "            return (F.softmax(ordre, dim=1), F.softmax(famille, dim=1), \n",
    "                   F.softmax(genre, dim=1), F.softmax(espece, dim=1))\n",
    "        \n",
    "        # Stack [B, 4, max_classes] â†’ pad Ã  max\n",
    "        max_classes = 2526\n",
    "        preds = torch.zeros(x.size(0), 4, max_classes, device=x.device)\n",
    "        preds[:, 0, :ordre.size(1)] = ordre\n",
    "        preds[:, 1, :famille.size(1)] = famille\n",
    "        preds[:, 2, :genre.size(1)] = genre\n",
    "        preds[:, 3, :espece.size(1)] = espece\n",
    "        \n",
    "        return preds  # [B,4,2526]\n",
    "\n",
    "# === STATS ===\n",
    "with open('hierarchy_labels.json') as f:\n",
    "    stats = json.load(f)['stats']\n",
    "num_ordre = stats['ordres']      # 17\n",
    "num_famille = stats['familles']  # 190\n",
    "num_genre = stats['genres']     # 1472\n",
    "num_espece = stats['total_classes']  # 2526\n",
    "\n",
    "# Model\n",
    "model = HierarchicalMobileNetV3(num_ordre, num_famille, num_genre, num_espece).to(device)\n",
    "\n",
    "class HierarchicalLoss(nn.Module):\n",
    "    def __init__(self, num_classes_per_level):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.weights = torch.tensor([1.0, 2.0, 5.0, 10.0])\n",
    "        self.num_classes = num_classes_per_level  # [17,190,1472,2526]\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        loss = 0\n",
    "        for i in range(4):\n",
    "            mask = torch.arange(self.num_classes[i], device=preds.device)\n",
    "            lvl_pred = preds[:, i, mask]\n",
    "            lvl_loss = self.ce(lvl_pred, targets[:, i])\n",
    "            loss += self.weights[i] * lvl_loss\n",
    "        return loss / self.weights.sum()\n",
    "\n",
    "criterion = HierarchicalLoss([num_ordre, num_famille, num_genre, num_espece])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(f\"Model: {sum(p.numel() for p in model.parameters()):,} params\")\n",
    "print(f\"âœ… GPU: {next(model.parameters()).device}\")\n",
    "\n",
    "# TEST FIX\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batch_img, batch_labels = next(iter(train_loader))\n",
    "    preds = model(batch_img.to(device))  # [32,4,2526]\n",
    "    loss = criterion(preds, batch_labels.to(device))\n",
    "    print(f\"âœ… Test OK: preds={preds.shape}, loss={loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T14:39:26.456563Z",
     "iopub.status.busy": "2026-01-11T14:39:26.456230Z",
     "iopub.status.idle": "2026-01-11T14:39:26.463744Z",
     "shell.execute_reply": "2026-01-11T14:39:26.462600Z",
     "shell.execute_reply.started": "2026-01-11T14:39:26.456535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HierarchicalLoss(nn.Module):\n",
    "    def __init__(self, weights=[1.0, 1.5, 2.0, 3.0]):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.weights = weights\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        ordre_p, fam_p, genre_p, esp_p = preds\n",
    "        ordre_t, fam_t, genre_t, esp_t = targets[:, 0], targets[:, 1], targets[:, 2], targets[:, 3]\n",
    "        \n",
    "        loss0 = self.ce(ordre_p, ordre_t)\n",
    "        loss1 = self.ce(fam_p, fam_t)\n",
    "        loss2 = self.ce(genre_p, genre_t)\n",
    "        loss3 = self.ce(esp_p, esp_t)\n",
    "        \n",
    "        return sum(w * l for w, l in zip(self.weights, [loss0, loss1, loss2, loss3]))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8808792,
     "sourceId": 13841637,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
