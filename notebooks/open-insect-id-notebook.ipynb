{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13841637,"sourceType":"datasetVersion","datasetId":8808792}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yoanndev90/open-insect-id-notebook?scriptVersionId=293675670\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"pip install ijson","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T13:07:46.754009Z","iopub.execute_input":"2026-01-24T13:07:46.754329Z","iopub.status.idle":"2026-01-24T13:07:53.316193Z","shell.execute_reply.started":"2026-01-24T13:07:46.754304Z","shell.execute_reply":"2026-01-24T13:07:53.314951Z"}},"outputs":[{"name":"stdout","text":"Collecting ijson\n  Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\nDownloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ijson\nSuccessfully installed ijson-3.4.0.post0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport json\nimport glob\nimport re\nfrom pathlib import Path\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nfrom collections import Counter, defaultdict\nimport ijson\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport time","metadata":{"execution":{"iopub.status.busy":"2026-01-24T13:07:54.673363Z","iopub.execute_input":"2026-01-24T13:07:54.673801Z","iopub.status.idle":"2026-01-24T13:07:54.69123Z","shell.execute_reply.started":"2026-01-24T13:07:54.673752Z","shell.execute_reply":"2026-01-24T13:07:54.690059Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!ls -la /kaggle/input/utility-scripts-80b72cee7e\n\n!jupyter nbconvert --to python /kaggle/input/utility-scripts-80b72cee7e/__notebook__.ipynb --output-dir=/kaggle/working --output=utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T13:07:58.865335Z","iopub.execute_input":"2026-01-24T13:07:58.865819Z","iopub.status.idle":"2026-01-24T13:08:03.946854Z","shell.execute_reply.started":"2026-01-24T13:07:58.865788Z","shell.execute_reply":"2026-01-24T13:08:03.94542Z"}},"outputs":[{"name":"stdout","text":"total 368\ndrwxr-xr-x 2 nobody nogroup      0 Jan 24 13:07 .\ndrwxr-xr-x 4 root   root      4096 Jan 24 12:57 ..\n-rw-r--r-- 1 nobody nogroup      0 Jan 24 13:07 custom.css\n-rw-r--r-- 1 nobody nogroup  25031 Jan 24 13:07 __notebook__.ipynb\n-rw-r--r-- 1 nobody nogroup   2949 Jan 24 13:07 __output__.json\n-rw-r--r-- 1 nobody nogroup 338773 Jan 24 13:07 __results__.html\n/usr/local/lib/python3.12/dist-packages/mistune.py:435: SyntaxWarning: invalid escape sequence '\\|'\n  cells[i][c] = re.sub('\\\\\\\\\\|', '|', cell)\n/usr/local/lib/python3.12/dist-packages/nbconvert/filters/filter_links.py:36: SyntaxWarning: invalid escape sequence '\\_'\n  text = re.sub(r'_', '\\_', text) # Escape underscores in display text\n[NbConvertApp] Converting notebook /kaggle/input/utility-scripts-80b72cee7e/__notebook__.ipynb to python\n[NbConvertApp] Writing 16309 bytes to /kaggle/working/utils.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working')\nfrom utils import *\n\n# Liste toutes les fonctions/variables importées (sans underscore privé)\nimported_funcs = [name for name in dir() if not name.startswith('_') and callable(globals()[name])]\nprint(\"Fonctions importées :\", imported_funcs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T13:09:52.062822Z","iopub.execute_input":"2026-01-24T13:09:52.063182Z","iopub.status.idle":"2026-01-24T13:09:52.070789Z","shell.execute_reply.started":"2026-01-24T13:09:52.063155Z","shell.execute_reply":"2026-01-24T13:09:52.069841Z"}},"outputs":[{"name":"stdout","text":"Fonctions importées : ['Counter', 'DataLoader', 'Dataset', 'Path', 'ThreadPoolExecutor', 'as_completed', 'build_hierarchy_labels', 'build_taxa_maps', 'defaultdict', 'exit', 'get_ipython', 'parse_taxonomy', 'parse_taxonomy_folders', 'quit', 'save_hierarchy_map', 'scan_corrupted_images', 'tree', 'verify_image_validity']\nTous les items importés : ['Counter', 'DataLoader', 'Dataset', 'F', 'Image', 'In', 'Out', 'Path', 'ThreadPoolExecutor', 'as_completed', 'base_folder', 'build_hierarchy_labels', 'build_taxa_maps', 'datasets', 'defaultdict', 'dill', 'example', 'exit', 'get_ipython', 'glob', 'hierarchy_map_file', 'ijson', 'imported_funcs', 'json', 'models', 'nn', 'os', 'parse_taxonomy', 'parse_taxonomy_folders', 'pd', 'public_test_folder', 'public_test_json', 'quit', 're', 'save_hierarchy_map', 'scan_corrupted_images', 'sys', 'taxonomy', 'time', 'torch', 'train_folder', 'train_json', 'train_mini_folder', 'train_mini_json', 'transforms', 'tree', 'tree_file', 'utils', 'val_folder', 'val_json', 'verify_image_validity', 'working_dir']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Input files\nbase_folder = \"/kaggle/input/inaturalist-insects/\"\n\npublic_test_folder = os.path.join(base_folder, \"public_test/public_test\")\ntrain_folder = os.path.join(base_folder, \"train/train\")\ntrain_mini_folder = os.path.join(base_folder, \"train_mini/train_mini\")\nval_folder = os.path.join(base_folder, \"val/val\")\n\npublic_test_json = os.path.join(base_folder, \"public_test-json/public_test.json\")\ntrain_json = os.path.join(base_folder, \"train-json/train.json\")\ntrain_mini_json = os.path.join(base_folder, \"train_mini-json/train_mini.json\")\nval_json = os.path.join(base_folder, \"val-json/val.json\")\n\n# Output files\nworking_dir = \"/kaggle/working/\"\n\ntree_file = os.path.join(working_dir, \"tree.txt\")\nhierarchy_map_file = \"/kaggle/working/hierarchy_map.json\"","metadata":{"execution":{"iopub.status.busy":"2026-01-24T13:08:42.254162Z","iopub.execute_input":"2026-01-24T13:08:42.254733Z","iopub.status.idle":"2026-01-24T13:08:42.268931Z","shell.execute_reply.started":"2026-01-24T13:08:42.254682Z","shell.execute_reply":"2026-01-24T13:08:42.267713Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"example = \"train/train/00980_Animalia_Arthropoda_Insecta_Lepidoptera_Erebidae_Arctia_virginalis/464f3a34-4c04-4eb3-afa2-6cb7444c3fa3.jpg\"\ntaxonomy = parse_taxonomy(example)\nprint(\"Résultat:\", taxonomy)\nvalidity = verify_image_validity(example)\nprint(\"Image valide\" if validity else \"Image invalide\")","metadata":{"execution":{"iopub.status.busy":"2026-01-24T13:10:12.87304Z","iopub.execute_input":"2026-01-24T13:10:12.873892Z","iopub.status.idle":"2026-01-24T13:10:12.879674Z","shell.execute_reply.started":"2026-01-24T13:10:12.873855Z","shell.execute_reply":"2026-01-24T13:10:12.878722Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Résultat: {'ordre': 'Lepidoptera', 'famille': 'Erebidae', 'genre': 'Arctia', 'espece': 'virginalis'}\nImage valide\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"total = tree(base_folder, 2)\nprint(f\"\\nNombre total de fichiers : {total}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-24T13:10:15.003586Z","iopub.execute_input":"2026-01-24T13:10:15.004771Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = '/kaggle/input/inaturalist-insects/'\nhierarchy_map_file = '/kaggle/working/hierarchy_map.json'\nfinal_hierarchy = build_hierarchy_labels(data_dir, hierarchy_map_file)\n\nprint(\"\\nExemples:\")\nfor idx in range(25):\n    labels = final_hierarchy.get(idx)\n    print(f\"Class {idx}: {labels}\") # [ordre_id, famille_id, genre_id, espece_id]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_annotated_images(json_path):\n    \"\"\"Charge lat/lon par file_name depuis train_mini_json.\"\"\"\n    annotated = {}\n    with open(json_path, 'rb') as f:\n        parser = ijson.items(f, 'images.item')\n        for img in parser:\n            filename = img.get('file_name', '')\n            lat = float(img.get('latitude')) if img.get('latitude') is not None else 0.0\n            lon = float(img.get('longitude')) if img.get('longitude') is not None else 0.0\n            annotated[filename] = (lat, lon)\n    return annotated","metadata":{"execution":{"iopub.execute_input":"2026-01-11T11:19:23.774461Z","iopub.status.busy":"2026-01-11T11:19:23.774184Z","iopub.status.idle":"2026-01-11T11:19:23.779579Z","shell.execute_reply":"2026-01-11T11:19:23.778726Z","shell.execute_reply.started":"2026-01-11T11:19:23.77444Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_stats(full_taxa_map, full_geo_db, species_encountered):\n    \"\"\"Calcule toutes stats.\"\"\"\n    ordre_count = Counter()\n    famille_count = Counter()\n    genre_count = Counter()\n    espece_count = Counter()\n    \n    for taxon_key, hier in full_taxa_map.items():\n        ordre_count[hier['ordre']] += 1\n        famille_count[hier['famille']] += 1\n        genre_count[hier['genre']] += 1\n        espece_count[hier['espece']] += 1\n    \n    homonyms_count = len([s for s in species_encountered if len(species_encountered[s]) > 1])\n    homonyms_dirs = sum(len(species_encountered[s]) for s in species_encountered if len(species_encountered[s]) > 1)\n    \n    taxon_geo_counts = {str(k): len(v) for k, v in full_geo_db.items()}\n    geo_taxa = len(full_geo_db)\n    total_taxa = len(full_taxa_map)\n    multi_geo = sum(1 for c in taxon_geo_counts.values() if c > 1)\n    \n    return {\n        'total_dirs': len(species_encountered),\n        'unique_taxa': total_taxa,\n        'geo_coverage': geo_taxa / total_taxa if total_taxa else 0,\n        'homonyms': {'names': homonyms_count, 'dirs': homonyms_dirs},\n        'hierarchy': {\n            'ordres': len(ordre_count), 'familles': len(famille_count), 'genres': len(genre_count)\n        },\n        'taxon_geo_counts': taxon_geo_counts\n    }, ordre_count, famille_count, genre_count","metadata":{"execution":{"iopub.execute_input":"2026-01-11T11:19:31.985291Z","iopub.status.busy":"2026-01-11T11:19:31.98487Z","iopub.status.idle":"2026-01-11T11:19:31.993632Z","shell.execute_reply":"2026-01-11T11:19:31.992596Z","shell.execute_reply.started":"2026-01-11T11:19:31.985261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"annotated_images = load_annotated_images(train_mini_json)\nspecies_encountered, unparsed_dirs = parse_taxonomy_folders(train_mini_folder)\nfull_taxa_map, full_geo_db = build_taxa_maps(species_encountered, annotated_images, train_mini_folder)\nstats, ordre_count, famille_count, genre_count = compute_stats(full_taxa_map, full_geo_db, species_encountered)\n\nprint(f\"✅ {stats['unique_taxa']} taxons (sur {stats['total_dirs']} dossiers)\")\nprint(f\"Homonymes: {stats['homonyms']['names']} noms → {stats['homonyms']['dirs']} dossiers\")\nprint(f\"Hiérarchie: {stats['hierarchy']['ordres']} ordres, {stats['hierarchy']['familles']} familles, {stats['hierarchy']['genres']} genres\")\nprint(f\"Géo: {len(full_geo_db)}/{len(full_taxa_map)} ({stats['geo_coverage']*100:.1f}%)\")\nprint(f\"Non parsés: {len(unparsed_dirs)}\")\n\nsave_hierarchy_map(full_taxa_map, full_geo_db, stats, hierarchy_map_file)","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2026-01-11T11:31:04.266165Z","iopub.status.busy":"2026-01-11T11:31:04.26537Z","iopub.status.idle":"2026-01-11T11:31:10.026437Z","shell.execute_reply":"2026-01-11T11:31:10.025528Z","shell.execute_reply.started":"2026-01-11T11:31:04.266136Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RobustImageFolder(Dataset):\n    \"\"\"ImageFolder skip corrompus.\"\"\"\n    def __init__(self, root, transform=None, corrupt_files=None):\n        self.root = root\n        self.transform = transform\n        self.corrupt_files = set(corrupt_files or [])\n        \n        self.classes, self.class_to_idx = self.find_classes(self.root)\n        self.samples = self.make_dataset(self.root, self.class_to_idx)\n        \n        self.valid_indices = []\n        for i, (path, _) in enumerate(self.samples):\n            if os.path.relpath(path, self.root) not in self.corrupt_files:\n                self.valid_indices.append(i)\n    \n    def find_classes(self, directory):\n        \"\"\"Trouve classes (dossiers).\"\"\"\n        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n        return classes, class_to_idx\n    \n    def make_dataset(self, directory, class_to_idx):\n        \"\"\"Construit samples comme ImageFolder.\"\"\"\n        samples = []\n        for target_class in sorted(self.class_to_idx.keys()):\n            class_index = self.class_to_idx[target_class]\n            target_dir = os.path.join(directory, target_class)\n            for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root, fname)\n                    item = (path, class_index)\n                    samples.append(item)\n        return samples\n    \n    def __getitem__(self, index):\n        path, target = self.samples[self.valid_indices[index]]\n        img = Image.open(path).convert(\"RGB\")\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n    \n    def __len__(self):\n        return len(self.valid_indices)","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:29:14.223558Z","iopub.status.busy":"2026-01-11T14:29:14.223257Z","iopub.status.idle":"2026-01-11T14:29:14.233873Z","shell.execute_reply":"2026-01-11T14:29:14.232695Z","shell.execute_reply.started":"2026-01-11T14:29:14.223536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corrupted_train, train_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/train_mini/train_mini', max_workers=4)\ncorrupted_val, val_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/val/val', max_workers=4)\n\nwith open(train_log) as f:\n    print(\"\\nCORROMPUS TRAIN:\\n\", f.read()[:500] + \"...\" if os.path.getsize(train_log) > 500 else f.read())","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:10:31.060279Z","iopub.status.busy":"2026-01-11T14:10:31.060006Z","iopub.status.idle":"2026-01-11T14:19:58.673901Z","shell.execute_reply":"2026-01-11T14:19:58.672672Z","shell.execute_reply.started":"2026-01-11T14:10:31.060263Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corrupt_train = []\nwith open('/kaggle/working/corrupted_train_mini.txt') as f:\n    for line in f:\n        if line.strip() and not line.startswith('#'):\n            corrupt_train.append(line.strip())\n\ncorrupt_val = []\nwith open('/kaggle/working/corrupted_val.txt') as f:\n    for line in f:\n        if line.strip() and not line.startswith('#'):\n            corrupt_val.append(line.strip())","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:29:21.524378Z","iopub.status.busy":"2026-01-11T14:29:21.524063Z","iopub.status.idle":"2026-01-11T14:29:21.534947Z","shell.execute_reply":"2026-01-11T14:29:21.534373Z","shell.execute_reply.started":"2026-01-11T14:29:21.524359Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Datasets FULL (sans skip)\ntrain_dataset_full = RobustImageFolder(train_mini_folder)\nval_dataset_full = RobustImageFolder(val_folder)\n\n# Datasets CLEAN\ntrain_dataset = RobustImageFolder(train_mini_folder, train_transforms, corrupt_train)\nval_dataset = RobustImageFolder(val_folder, val_transforms, corrupt_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n\nprint(f'Train: {len(train_dataset_full)} → {len(train_dataset)}')\nprint(f'Val: {len(val_dataset_full)} → {len(val_dataset)}')\nprint(f'Classes: {len(train_dataset.classes)}')","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:29:24.768465Z","iopub.status.busy":"2026-01-11T14:29:24.768169Z","iopub.status.idle":"2026-01-11T14:30:36.718824Z","shell.execute_reply":"2026-01-11T14:30:36.71772Z","shell.execute_reply.started":"2026-01-11T14:29:24.768449Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\n\n# Transforms\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(30),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.3),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nclass HierarchicalInsectDataset(Dataset):\n    def __init__(self, root_dir, hierarchy_map, transform=None, corrupt_files=None):\n        self.root_dir = root_dir\n        self.hierarchy_map = hierarchy_map\n        self.transform = transform\n        \n        # ImageFolder interne\n        self.inner_dataset = datasets.ImageFolder(root_dir)\n        \n        # Filtre corrompus + hiérarchie\n        self.valid_indices = []\n        for i in range(len(self.inner_dataset)):\n            class_idx = self.inner_dataset.targets[i]\n            if class_idx in self.hierarchy_map:\n                # Skip si basename dans corrupt_files\n                path = self.inner_dataset.samples[i][0]\n                if os.path.basename(path) not in (corrupt_files or []):\n                    self.valid_indices.append(i)\n        \n        print(f\"Dataset {root_dir}: {len(self.inner_dataset)} → {len(self.valid_indices)} valides\")\n    \n    def __getitem__(self, idx):\n        real_idx = self.valid_indices[idx]\n        img, class_idx = self.inner_dataset[real_idx]\n        \n        # Labels hiérarchiques [ordre_id, famille_id, genre_id, espece_id]\n        hier_labels = torch.tensor(self.hierarchy_map[class_idx])\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        return img, hier_labels\n    \n    def __len__(self):\n        return len(self.valid_indices)\n\n# === USAGE ===\ndata_dir = '/kaggle/input/inaturalist-insects/'\ntrain_mini_folder = os.path.join(data_dir, 'train_mini/train_mini')\nval_folder = os.path.join(data_dir, 'val/val')\n\n# Datasets hiérarchiques\ntrain_dataset = HierarchicalInsectDataset(\n    train_mini_folder, \n    final_hierarchy, \n    transform=train_transforms,\n    corrupt_files=[os.path.basename(p) for p in corrupt_train]  # Seulement basenames\n)\n\nval_dataset = HierarchicalInsectDataset(\n    val_folder, \n    final_hierarchy, \n    transform=val_transforms,\n    corrupt_files=[os.path.basename(p) for p in corrupt_val]\n)\n\n# Loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"✅ Datasets hiérarchiques:\")\nprint(f\"  Train: {len(train_dataset)} images, 2526 classes\")\nprint(f\"  Val: {len(val_dataset)} images\")\nprint(f\"  Labels: ordre/famille/genre/espece [device={device}]\")\n\n# Test 1 batch\nimg, labels = next(iter(train_loader))\nprint(f\"Batch shape: {img.shape}, labels shape: {labels.shape}\")  # [32,3,224,224], [32,4]","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:32:18.908926Z","iopub.status.busy":"2026-01-11T14:32:18.908611Z","iopub.status.idle":"2026-01-11T14:32:26.633926Z","shell.execute_reply":"2026-01-11T14:32:26.632914Z","shell.execute_reply.started":"2026-01-11T14:32:18.908908Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport json\n\nclass HierarchicalMobileNetV3(nn.Module):\n    \"\"\"MobileNetV3 avec outputs séparés par niveau.\"\"\"\n    def __init__(self, num_ordre=17, num_famille=190, num_genre=1472, num_espece=2526):\n        super().__init__()\n        backbone = models.mobilenet_v3_large(weights='IMAGENET1K_V1')\n        self.features = backbone.features\n        self.avgpool = backbone.avgpool\n        \n        self.fc_shared = nn.Sequential(\n            nn.Linear(960, 512),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.3)\n        )\n        \n        # Heads indépendants (FIX: pas cumulatif)\n        self.head_ordre = nn.Linear(512, num_ordre)\n        self.head_famille = nn.Linear(512, num_famille)\n        self.head_genre = nn.Linear(512, num_genre)\n        self.head_espece = nn.Linear(512, num_espece)\n    \n    def forward(self, x, return_probs=False):\n        x = self.features(x)\n        x = self.avgpool(x)\n        feats = torch.flatten(x, 1)\n        shared = self.fc_shared(feats)\n        \n        ordre = self.head_ordre(shared)\n        famille = self.head_famille(shared)\n        genre = self.head_genre(shared)\n        espece = self.head_espece(shared)\n        \n        if return_probs:\n            return (F.softmax(ordre, dim=1), F.softmax(famille, dim=1), \n                   F.softmax(genre, dim=1), F.softmax(espece, dim=1))\n        \n        # Stack [B, 4, max_classes] → pad à max\n        max_classes = 2526\n        preds = torch.zeros(x.size(0), 4, max_classes, device=x.device)\n        preds[:, 0, :ordre.size(1)] = ordre\n        preds[:, 1, :famille.size(1)] = famille\n        preds[:, 2, :genre.size(1)] = genre\n        preds[:, 3, :espece.size(1)] = espece\n        \n        return preds  # [B,4,2526]\n\n# === STATS ===\nwith open('hierarchy_labels.json') as f:\n    stats = json.load(f)['stats']\nnum_ordre = stats['ordres']      # 17\nnum_famille = stats['familles']  # 190\nnum_genre = stats['genres']     # 1472\nnum_espece = stats['total_classes']  # 2526\n\n# Model\nmodel = HierarchicalMobileNetV3(num_ordre, num_famille, num_genre, num_espece).to(device)\n\nclass HierarchicalLoss(nn.Module):\n    def __init__(self, num_classes_per_level):\n        super().__init__()\n        self.ce = nn.CrossEntropyLoss()\n        self.weights = torch.tensor([1.0, 2.0, 5.0, 10.0])\n        self.num_classes = num_classes_per_level  # [17,190,1472,2526]\n    \n    def forward(self, preds, targets):\n        loss = 0\n        for i in range(4):\n            mask = torch.arange(self.num_classes[i], device=preds.device)\n            lvl_pred = preds[:, i, mask]\n            lvl_loss = self.ce(lvl_pred, targets[:, i])\n            loss += self.weights[i] * lvl_loss\n        return loss / self.weights.sum()\n\ncriterion = HierarchicalLoss([num_ordre, num_famille, num_genre, num_espece])\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\nprint(f\"Model: {sum(p.numel() for p in model.parameters()):,} params\")\nprint(f\"✅ GPU: {next(model.parameters()).device}\")\n\n# TEST FIX\nmodel.eval()\nwith torch.no_grad():\n    batch_img, batch_labels = next(iter(train_loader))\n    preds = model(batch_img.to(device))  # [32,4,2526]\n    loss = criterion(preds, batch_labels.to(device))\n    print(f\"✅ Test OK: preds={preds.shape}, loss={loss.item():.3f}\")","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:39:06.995036Z","iopub.status.busy":"2026-01-11T14:39:06.994708Z","iopub.status.idle":"2026-01-11T14:39:08.93406Z","shell.execute_reply":"2026-01-11T14:39:08.933051Z","shell.execute_reply.started":"2026-01-11T14:39:06.995017Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HierarchicalLoss(nn.Module):\n    def __init__(self, weights=[1.0, 1.5, 2.0, 3.0]):\n        super().__init__()\n        self.ce = nn.CrossEntropyLoss()\n        self.weights = weights\n    \n    def forward(self, preds, targets):\n        ordre_p, fam_p, genre_p, esp_p = preds\n        ordre_t, fam_t, genre_t, esp_t = targets[:, 0], targets[:, 1], targets[:, 2], targets[:, 3]\n        \n        loss0 = self.ce(ordre_p, ordre_t)\n        loss1 = self.ce(fam_p, fam_t)\n        loss2 = self.ce(genre_p, genre_t)\n        loss3 = self.ce(esp_p, esp_t)\n        \n        return sum(w * l for w, l in zip(self.weights, [loss0, loss1, loss2, loss3]))","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:39:26.456563Z","iopub.status.busy":"2026-01-11T14:39:26.45623Z","iopub.status.idle":"2026-01-11T14:39:26.463744Z","shell.execute_reply":"2026-01-11T14:39:26.4626Z","shell.execute_reply.started":"2026-01-11T14:39:26.456535Z"},"trusted":true},"outputs":[],"execution_count":null}]}