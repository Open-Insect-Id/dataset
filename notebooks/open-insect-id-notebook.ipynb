{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13841637,"sourceType":"datasetVersion","datasetId":8808792}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yoanndev90/open-insect-id-notebook?scriptVersionId=293665640\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"pip install ijson nbconvert","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T12:06:21.981154Z","iopub.execute_input":"2026-01-24T12:06:21.9816Z","iopub.status.idle":"2026-01-24T12:06:26.690149Z","shell.execute_reply.started":"2026-01-24T12:06:21.981569Z","shell.execute_reply":"2026-01-24T12:06:26.688943Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ijson in /usr/local/lib/python3.12/dist-packages (3.4.0.post0)\nRequirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (6.4.5)\nRequirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.8.4)\nRequirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.1.6)\nRequirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (2.19.2)\nRequirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.3.0)\nRequirement already satisfied: traitlets>=5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.7.1)\nRequirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.9.1)\nRequirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.10.4)\nRequirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.4)\nRequirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from nbconvert) (6.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (1.5.1)\nRequirement already satisfied: testpath in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.6.0)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (4.13.5)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.0.3)\nRequirement already satisfied: jupyter-client>=6.1.5 in /usr/local/lib/python3.12/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (7.4.9)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.6.0)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.4->nbconvert) (2.21.2)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.4->nbconvert) (4.25.1)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core->nbconvert) (4.5.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert) (2.8)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert) (4.15.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach->nbconvert) (0.5.1)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (0.27.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (2.9.0.post0)\nRequirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (26.2.1)\nRequirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (6.5.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import os\nimport json\nimport glob\nimport re\nfrom pathlib import Path\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nfrom collections import Counter, defaultdict\nimport ijson\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport time","metadata":{"execution":{"iopub.status.busy":"2026-01-24T11:54:55.529997Z","iopub.execute_input":"2026-01-24T11:54:55.530349Z","iopub.status.idle":"2026-01-24T11:55:09.260109Z","shell.execute_reply.started":"2026-01-24T11:54:55.530316Z","shell.execute_reply":"2026-01-24T11:55:09.259092Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!ls -la /kaggle/input/utility-scripts-80b72cee7e\n\n!jupyter nbconvert --to python /kaggle/input/utility-scripts-80b72cee7e/__notebook__.ipynb --output-dir=/kaggle/working --output=utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T12:08:57.579826Z","iopub.execute_input":"2026-01-24T12:08:57.580265Z","iopub.status.idle":"2026-01-24T12:09:01.995152Z","shell.execute_reply.started":"2026-01-24T12:08:57.580216Z","shell.execute_reply":"2026-01-24T12:09:01.993865Z"}},"outputs":[{"name":"stdout","text":"total 368\ndrwxr-xr-x 2 nobody nogroup      0 Jan 24 11:45 .\ndrwxr-xr-x 4 root   root      4096 Jan 24 11:45 ..\n-rw-r--r-- 1 nobody nogroup      0 Jan 24 11:45 custom.css\n-rw-r--r-- 1 nobody nogroup  21782 Jan 24 11:45 __notebook__.ipynb\n-rw-r--r-- 1 nobody nogroup   3723 Jan 24 11:45 __output__.json\n-rw-r--r-- 1 nobody nogroup 340225 Jan 24 11:45 __results__.html\n[NbConvertApp] Converting notebook /kaggle/input/utility-scripts-80b72cee7e/__notebook__.ipynb to python\n[NbConvertApp] Writing 16585 bytes to /kaggle/working/utils.py\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working')\nimport utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T12:09:03.84808Z","iopub.execute_input":"2026-01-24T12:09:03.848481Z","iopub.status.idle":"2026-01-24T12:09:06.815577Z","shell.execute_reply.started":"2026-01-24T12:09:03.848446Z","shell.execute_reply":"2026-01-24T12:09:06.814033Z"}},"outputs":[{"name":"stdout","text":"Classes: 2526 (scan /kaggle/input/inaturalist-insects/train_mini/train_mini)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/239645822.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/kaggle/working/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/inaturalist-insects/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0mhierarchy_map_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/working/hierarchy_map.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m \u001b[0mfinal_hierarchy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_hierarchy_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhierarchy_map_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nExemples:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/utils.py\u001b[0m in \u001b[0;36mbuild_hierarchy_labels\u001b[0;34m(data_dir, hierarchy_map_file)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# 2. Hiérarchie depuis JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhierarchy_map_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/hierarchy_map.json'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/hierarchy_map.json'","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"# Input files\nbase_folder = \"/kaggle/input/inaturalist-insects/\"\n\npublic_test_folder = os.path.join(base_folder, \"public_test/public_test\")\ntrain_folder = os.path.join(base_folder, \"train/train\")\ntrain_mini_folder = os.path.join(base_folder, \"train_mini/train_mini\")\nval_folder = os.path.join(base_folder, \"val/val\")\n\npublic_test_json = os.path.join(base_folder, \"public_test-json/public_test.json\")\ntrain_json = os.path.join(base_folder, \"train-json/train.json\")\ntrain_mini_json = os.path.join(base_folder, \"train_mini-json/train_mini.json\")\nval_json = os.path.join(base_folder, \"val-json/val.json\")\n\n# Output files\nworking_dir = \"/kaggle/working/\"\n\ntree_file = os.path.join(working_dir, \"tree.txt\")\nhierarchy_map_file = \"/kaggle/working/hierarchy_map.json\"","metadata":{"execution":{"iopub.execute_input":"2026-01-11T12:52:54.378118Z","iopub.status.busy":"2026-01-11T12:52:54.377843Z","iopub.status.idle":"2026-01-11T12:52:54.38361Z","shell.execute_reply":"2026-01-11T12:52:54.382186Z","shell.execute_reply.started":"2026-01-11T12:52:54.378105Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"example = \"train/train/00980_Animalia_Arthropoda_Insecta_Lepidoptera_Erebidae_Arctia_virginalis/464f3a34-4c04-4eb3-afa2-6cb7444c3fa3.jpg\"\ntaxonomy = parse_taxonomy(example)\nprint(\"Résultat:\", taxonomy)\nvalidity = verify_image_validy(example)\nprint(\"Image valide\" if validity else \"Image invalide\")","metadata":{"execution":{"iopub.status.busy":"2026-01-24T11:57:18.326242Z","iopub.execute_input":"2026-01-24T11:57:18.326619Z","iopub.status.idle":"2026-01-24T11:57:18.334604Z","shell.execute_reply.started":"2026-01-24T11:57:18.326571Z","shell.execute_reply":"2026-01-24T11:57:18.333402Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1433701873.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train/train/00980_Animalia_Arthropoda_Insecta_Lepidoptera_Erebidae_Arctia_virginalis/464f3a34-4c04-4eb3-afa2-6cb7444c3fa3.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtaxonomy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_taxonomy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Résultat:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaxonomy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_image_validy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image valide\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalidity\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"Image invalide\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'parse_taxonomy' is not defined"],"ename":"NameError","evalue":"name 'parse_taxonomy' is not defined","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"total = tree(base_folder, 2)\nprint(f\"\\nNombre total de fichiers : {total}\")","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2026-01-11T09:20:29.374015Z","iopub.status.busy":"2026-01-11T09:20:29.373687Z","iopub.status.idle":"2026-01-11T09:56:28.751665Z","shell.execute_reply":"2026-01-11T09:56:28.75062Z","shell.execute_reply.started":"2026-01-11T09:20:29.373991Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_annotated_images(json_path):\n    \"\"\"Charge lat/lon par file_name depuis train_mini_json.\"\"\"\n    annotated = {}\n    with open(json_path, 'rb') as f:\n        parser = ijson.items(f, 'images.item')\n        for img in parser:\n            filename = img.get('file_name', '')\n            lat = float(img.get('latitude')) if img.get('latitude') is not None else 0.0\n            lon = float(img.get('longitude')) if img.get('longitude') is not None else 0.0\n            annotated[filename] = (lat, lon)\n    return annotated","metadata":{"execution":{"iopub.execute_input":"2026-01-11T11:19:23.774461Z","iopub.status.busy":"2026-01-11T11:19:23.774184Z","iopub.status.idle":"2026-01-11T11:19:23.779579Z","shell.execute_reply":"2026-01-11T11:19:23.778726Z","shell.execute_reply.started":"2026-01-11T11:19:23.77444Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_stats(full_taxa_map, full_geo_db, species_encountered):\n    \"\"\"Calcule toutes stats.\"\"\"\n    ordre_count = Counter()\n    famille_count = Counter()\n    genre_count = Counter()\n    espece_count = Counter()\n    \n    for taxon_key, hier in full_taxa_map.items():\n        ordre_count[hier['ordre']] += 1\n        famille_count[hier['famille']] += 1\n        genre_count[hier['genre']] += 1\n        espece_count[hier['espece']] += 1\n    \n    homonyms_count = len([s for s in species_encountered if len(species_encountered[s]) > 1])\n    homonyms_dirs = sum(len(species_encountered[s]) for s in species_encountered if len(species_encountered[s]) > 1)\n    \n    taxon_geo_counts = {str(k): len(v) for k, v in full_geo_db.items()}\n    geo_taxa = len(full_geo_db)\n    total_taxa = len(full_taxa_map)\n    multi_geo = sum(1 for c in taxon_geo_counts.values() if c > 1)\n    \n    return {\n        'total_dirs': len(species_encountered),\n        'unique_taxa': total_taxa,\n        'geo_coverage': geo_taxa / total_taxa if total_taxa else 0,\n        'homonyms': {'names': homonyms_count, 'dirs': homonyms_dirs},\n        'hierarchy': {\n            'ordres': len(ordre_count), 'familles': len(famille_count), 'genres': len(genre_count)\n        },\n        'taxon_geo_counts': taxon_geo_counts\n    }, ordre_count, famille_count, genre_count","metadata":{"execution":{"iopub.execute_input":"2026-01-11T11:19:31.985291Z","iopub.status.busy":"2026-01-11T11:19:31.98487Z","iopub.status.idle":"2026-01-11T11:19:31.993632Z","shell.execute_reply":"2026-01-11T11:19:31.992596Z","shell.execute_reply.started":"2026-01-11T11:19:31.985261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"annotated_images = load_annotated_images(train_mini_json)\nspecies_encountered, unparsed_dirs = parse_taxonomy_folders(train_mini_folder)\nfull_taxa_map, full_geo_db = build_taxa_maps(species_encountered, annotated_images, train_mini_folder)\nstats, ordre_count, famille_count, genre_count = compute_stats(full_taxa_map, full_geo_db, species_encountered)\n\nprint(f\"✅ {stats['unique_taxa']} taxons (sur {stats['total_dirs']} dossiers)\")\nprint(f\"Homonymes: {stats['homonyms']['names']} noms → {stats['homonyms']['dirs']} dossiers\")\nprint(f\"Hiérarchie: {stats['hierarchy']['ordres']} ordres, {stats['hierarchy']['familles']} familles, {stats['hierarchy']['genres']} genres\")\nprint(f\"Géo: {len(full_geo_db)}/{len(full_taxa_map)} ({stats['geo_coverage']*100:.1f}%)\")\nprint(f\"Non parsés: {len(unparsed_dirs)}\")\n\nsave_hierarchy_map(full_taxa_map, full_geo_db, stats, hierarchy_map_file)","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2026-01-11T11:31:04.266165Z","iopub.status.busy":"2026-01-11T11:31:04.26537Z","iopub.status.idle":"2026-01-11T11:31:10.026437Z","shell.execute_reply":"2026-01-11T11:31:10.025528Z","shell.execute_reply.started":"2026-01-11T11:31:04.266136Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RobustImageFolder(Dataset):\n    \"\"\"ImageFolder skip corrompus.\"\"\"\n    def __init__(self, root, transform=None, corrupt_files=None):\n        self.root = root\n        self.transform = transform\n        self.corrupt_files = set(corrupt_files or [])\n        \n        self.classes, self.class_to_idx = self.find_classes(self.root)\n        self.samples = self.make_dataset(self.root, self.class_to_idx)\n        \n        self.valid_indices = []\n        for i, (path, _) in enumerate(self.samples):\n            if os.path.relpath(path, self.root) not in self.corrupt_files:\n                self.valid_indices.append(i)\n    \n    def find_classes(self, directory):\n        \"\"\"Trouve classes (dossiers).\"\"\"\n        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n        return classes, class_to_idx\n    \n    def make_dataset(self, directory, class_to_idx):\n        \"\"\"Construit samples comme ImageFolder.\"\"\"\n        samples = []\n        for target_class in sorted(self.class_to_idx.keys()):\n            class_index = self.class_to_idx[target_class]\n            target_dir = os.path.join(directory, target_class)\n            for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root, fname)\n                    item = (path, class_index)\n                    samples.append(item)\n        return samples\n    \n    def __getitem__(self, index):\n        path, target = self.samples[self.valid_indices[index]]\n        img = Image.open(path).convert(\"RGB\")\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n    \n    def __len__(self):\n        return len(self.valid_indices)","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:29:14.223558Z","iopub.status.busy":"2026-01-11T14:29:14.223257Z","iopub.status.idle":"2026-01-11T14:29:14.233873Z","shell.execute_reply":"2026-01-11T14:29:14.232695Z","shell.execute_reply.started":"2026-01-11T14:29:14.223536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corrupted_train, train_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/train_mini/train_mini', max_workers=4)\ncorrupted_val, val_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/val/val', max_workers=4)\n\nwith open(train_log) as f:\n    print(\"\\nCORROMPUS TRAIN:\\n\", f.read()[:500] + \"...\" if os.path.getsize(train_log) > 500 else f.read())","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:10:31.060279Z","iopub.status.busy":"2026-01-11T14:10:31.060006Z","iopub.status.idle":"2026-01-11T14:19:58.673901Z","shell.execute_reply":"2026-01-11T14:19:58.672672Z","shell.execute_reply.started":"2026-01-11T14:10:31.060263Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corrupt_train = []\nwith open('/kaggle/working/corrupted_train_mini.txt') as f:\n    for line in f:\n        if line.strip() and not line.startswith('#'):\n            corrupt_train.append(line.strip())\n\ncorrupt_val = []\nwith open('/kaggle/working/corrupted_val.txt') as f:\n    for line in f:\n        if line.strip() and not line.startswith('#'):\n            corrupt_val.append(line.strip())","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:29:21.524378Z","iopub.status.busy":"2026-01-11T14:29:21.524063Z","iopub.status.idle":"2026-01-11T14:29:21.534947Z","shell.execute_reply":"2026-01-11T14:29:21.534373Z","shell.execute_reply.started":"2026-01-11T14:29:21.524359Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Datasets FULL (sans skip)\ntrain_dataset_full = RobustImageFolder(train_mini_folder)\nval_dataset_full = RobustImageFolder(val_folder)\n\n# Datasets CLEAN\ntrain_dataset = RobustImageFolder(train_mini_folder, train_transforms, corrupt_train)\nval_dataset = RobustImageFolder(val_folder, val_transforms, corrupt_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n\nprint(f'Train: {len(train_dataset_full)} → {len(train_dataset)}')\nprint(f'Val: {len(val_dataset_full)} → {len(val_dataset)}')\nprint(f'Classes: {len(train_dataset.classes)}')","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:29:24.768465Z","iopub.status.busy":"2026-01-11T14:29:24.768169Z","iopub.status.idle":"2026-01-11T14:30:36.718824Z","shell.execute_reply":"2026-01-11T14:30:36.71772Z","shell.execute_reply.started":"2026-01-11T14:29:24.768449Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\n\n# Transforms\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(30),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.3),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nclass HierarchicalInsectDataset(Dataset):\n    def __init__(self, root_dir, hierarchy_map, transform=None, corrupt_files=None):\n        self.root_dir = root_dir\n        self.hierarchy_map = hierarchy_map\n        self.transform = transform\n        \n        # ImageFolder interne\n        self.inner_dataset = datasets.ImageFolder(root_dir)\n        \n        # Filtre corrompus + hiérarchie\n        self.valid_indices = []\n        for i in range(len(self.inner_dataset)):\n            class_idx = self.inner_dataset.targets[i]\n            if class_idx in self.hierarchy_map:\n                # Skip si basename dans corrupt_files\n                path = self.inner_dataset.samples[i][0]\n                if os.path.basename(path) not in (corrupt_files or []):\n                    self.valid_indices.append(i)\n        \n        print(f\"Dataset {root_dir}: {len(self.inner_dataset)} → {len(self.valid_indices)} valides\")\n    \n    def __getitem__(self, idx):\n        real_idx = self.valid_indices[idx]\n        img, class_idx = self.inner_dataset[real_idx]\n        \n        # Labels hiérarchiques [ordre_id, famille_id, genre_id, espece_id]\n        hier_labels = torch.tensor(self.hierarchy_map[class_idx])\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        return img, hier_labels\n    \n    def __len__(self):\n        return len(self.valid_indices)\n\n# === USAGE ===\ndata_dir = '/kaggle/input/inaturalist-insects/'\ntrain_mini_folder = os.path.join(data_dir, 'train_mini/train_mini')\nval_folder = os.path.join(data_dir, 'val/val')\n\n# Datasets hiérarchiques\ntrain_dataset = HierarchicalInsectDataset(\n    train_mini_folder, \n    final_hierarchy, \n    transform=train_transforms,\n    corrupt_files=[os.path.basename(p) for p in corrupt_train]  # Seulement basenames\n)\n\nval_dataset = HierarchicalInsectDataset(\n    val_folder, \n    final_hierarchy, \n    transform=val_transforms,\n    corrupt_files=[os.path.basename(p) for p in corrupt_val]\n)\n\n# Loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"✅ Datasets hiérarchiques:\")\nprint(f\"  Train: {len(train_dataset)} images, 2526 classes\")\nprint(f\"  Val: {len(val_dataset)} images\")\nprint(f\"  Labels: ordre/famille/genre/espece [device={device}]\")\n\n# Test 1 batch\nimg, labels = next(iter(train_loader))\nprint(f\"Batch shape: {img.shape}, labels shape: {labels.shape}\")  # [32,3,224,224], [32,4]","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:32:18.908926Z","iopub.status.busy":"2026-01-11T14:32:18.908611Z","iopub.status.idle":"2026-01-11T14:32:26.633926Z","shell.execute_reply":"2026-01-11T14:32:26.632914Z","shell.execute_reply.started":"2026-01-11T14:32:18.908908Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport json\n\nclass HierarchicalMobileNetV3(nn.Module):\n    \"\"\"MobileNetV3 avec outputs séparés par niveau.\"\"\"\n    def __init__(self, num_ordre=17, num_famille=190, num_genre=1472, num_espece=2526):\n        super().__init__()\n        backbone = models.mobilenet_v3_large(weights='IMAGENET1K_V1')\n        self.features = backbone.features\n        self.avgpool = backbone.avgpool\n        \n        self.fc_shared = nn.Sequential(\n            nn.Linear(960, 512),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.3)\n        )\n        \n        # Heads indépendants (FIX: pas cumulatif)\n        self.head_ordre = nn.Linear(512, num_ordre)\n        self.head_famille = nn.Linear(512, num_famille)\n        self.head_genre = nn.Linear(512, num_genre)\n        self.head_espece = nn.Linear(512, num_espece)\n    \n    def forward(self, x, return_probs=False):\n        x = self.features(x)\n        x = self.avgpool(x)\n        feats = torch.flatten(x, 1)\n        shared = self.fc_shared(feats)\n        \n        ordre = self.head_ordre(shared)\n        famille = self.head_famille(shared)\n        genre = self.head_genre(shared)\n        espece = self.head_espece(shared)\n        \n        if return_probs:\n            return (F.softmax(ordre, dim=1), F.softmax(famille, dim=1), \n                   F.softmax(genre, dim=1), F.softmax(espece, dim=1))\n        \n        # Stack [B, 4, max_classes] → pad à max\n        max_classes = 2526\n        preds = torch.zeros(x.size(0), 4, max_classes, device=x.device)\n        preds[:, 0, :ordre.size(1)] = ordre\n        preds[:, 1, :famille.size(1)] = famille\n        preds[:, 2, :genre.size(1)] = genre\n        preds[:, 3, :espece.size(1)] = espece\n        \n        return preds  # [B,4,2526]\n\n# === STATS ===\nwith open('hierarchy_labels.json') as f:\n    stats = json.load(f)['stats']\nnum_ordre = stats['ordres']      # 17\nnum_famille = stats['familles']  # 190\nnum_genre = stats['genres']     # 1472\nnum_espece = stats['total_classes']  # 2526\n\n# Model\nmodel = HierarchicalMobileNetV3(num_ordre, num_famille, num_genre, num_espece).to(device)\n\nclass HierarchicalLoss(nn.Module):\n    def __init__(self, num_classes_per_level):\n        super().__init__()\n        self.ce = nn.CrossEntropyLoss()\n        self.weights = torch.tensor([1.0, 2.0, 5.0, 10.0])\n        self.num_classes = num_classes_per_level  # [17,190,1472,2526]\n    \n    def forward(self, preds, targets):\n        loss = 0\n        for i in range(4):\n            mask = torch.arange(self.num_classes[i], device=preds.device)\n            lvl_pred = preds[:, i, mask]\n            lvl_loss = self.ce(lvl_pred, targets[:, i])\n            loss += self.weights[i] * lvl_loss\n        return loss / self.weights.sum()\n\ncriterion = HierarchicalLoss([num_ordre, num_famille, num_genre, num_espece])\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\nprint(f\"Model: {sum(p.numel() for p in model.parameters()):,} params\")\nprint(f\"✅ GPU: {next(model.parameters()).device}\")\n\n# TEST FIX\nmodel.eval()\nwith torch.no_grad():\n    batch_img, batch_labels = next(iter(train_loader))\n    preds = model(batch_img.to(device))  # [32,4,2526]\n    loss = criterion(preds, batch_labels.to(device))\n    print(f\"✅ Test OK: preds={preds.shape}, loss={loss.item():.3f}\")","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:39:06.995036Z","iopub.status.busy":"2026-01-11T14:39:06.994708Z","iopub.status.idle":"2026-01-11T14:39:08.93406Z","shell.execute_reply":"2026-01-11T14:39:08.933051Z","shell.execute_reply.started":"2026-01-11T14:39:06.995017Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HierarchicalLoss(nn.Module):\n    def __init__(self, weights=[1.0, 1.5, 2.0, 3.0]):\n        super().__init__()\n        self.ce = nn.CrossEntropyLoss()\n        self.weights = weights\n    \n    def forward(self, preds, targets):\n        ordre_p, fam_p, genre_p, esp_p = preds\n        ordre_t, fam_t, genre_t, esp_t = targets[:, 0], targets[:, 1], targets[:, 2], targets[:, 3]\n        \n        loss0 = self.ce(ordre_p, ordre_t)\n        loss1 = self.ce(fam_p, fam_t)\n        loss2 = self.ce(genre_p, genre_t)\n        loss3 = self.ce(esp_p, esp_t)\n        \n        return sum(w * l for w, l in zip(self.weights, [loss0, loss1, loss2, loss3]))","metadata":{"execution":{"iopub.execute_input":"2026-01-11T14:39:26.456563Z","iopub.status.busy":"2026-01-11T14:39:26.45623Z","iopub.status.idle":"2026-01-11T14:39:26.463744Z","shell.execute_reply":"2026-01-11T14:39:26.4626Z","shell.execute_reply.started":"2026-01-11T14:39:26.456535Z"},"trusted":true},"outputs":[],"execution_count":null}]}