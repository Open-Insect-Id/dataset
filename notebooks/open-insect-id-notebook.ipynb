{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13841637,"sourceType":"datasetVersion","datasetId":8808792},{"sourceId":293711333,"sourceType":"kernelVersion"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yoanndev90/open-insect-id-notebook?scriptVersionId=297309511\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"pip install ijson","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2026-02-12T08:19:42.243892Z","iopub.execute_input":"2026-02-12T08:19:42.244792Z","iopub.status.idle":"2026-02-12T08:19:48.055784Z","shell.execute_reply.started":"2026-02-12T08:19:42.244756Z","shell.execute_reply":"2026-02-12T08:19:48.054597Z"}},"outputs":[{"name":"stdout","text":"Collecting ijson\n  Downloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\nDownloading ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ijson\nSuccessfully installed ijson-3.4.0.post0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport glob\nimport re\nfrom pathlib import Path\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport pandas as pd\nfrom collections import Counter, defaultdict\nimport ijson\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport time","metadata":{"execution":{"iopub.status.busy":"2026-02-12T08:19:50.203974Z","iopub.execute_input":"2026-02-12T08:19:50.204352Z","iopub.status.idle":"2026-02-12T08:19:59.575384Z","shell.execute_reply.started":"2026-02-12T08:19:50.204315Z","shell.execute_reply":"2026-02-12T08:19:59.574597Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working')\nfrom utils import *\n\nimported_funcs = [name for name in dir() if not name.startswith('_') and callable(globals()[name])]\nprint(\"Fonctions import√©es :\", imported_funcs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T08:20:02.42998Z","iopub.execute_input":"2026-02-12T08:20:02.430581Z","iopub.status.idle":"2026-02-12T08:20:02.444105Z","shell.execute_reply.started":"2026-02-12T08:20:02.430547Z","shell.execute_reply":"2026-02-12T08:20:02.44278Z"}},"outputs":[{"name":"stdout","text":"Fonctions import√©es : ['Counter', 'DataLoader', 'Dataset', 'Path', 'ThreadPoolExecutor', 'as_completed', 'build_hierarchy_labels', 'build_taxa_maps', 'defaultdict', 'exit', 'get_ipython', 'parse_taxonomy', 'parse_taxonomy_folders', 'quit', 'save_hierarchy_map', 'scan_corrupted_images', 'tree', 'verify_image_validity']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from utils import parse_taxonomy, verify_image_validity\n\nexample = \"train/train/00980_Animalia_Arthropoda_Insecta_Lepidoptera_Erebidae_Arctia_virginalis/464f3a34-4c04-4eb3-afa2-6cb7444c3fa3.jpg\"\ntaxonomy = parse_taxonomy(example)\nprint(\"R√©sultat:\", taxonomy)\nvalidity = verify_image_validity(example)\nprint(\"Image valide\" if validity else \"Image invalide\")","metadata":{"execution":{"iopub.status.busy":"2026-01-25T10:45:39.301987Z","iopub.execute_input":"2026-01-25T10:45:39.302746Z","iopub.status.idle":"2026-01-25T10:45:39.307577Z","shell.execute_reply.started":"2026-01-25T10:45:39.302718Z","shell.execute_reply":"2026-01-25T10:45:39.306879Z"},"trusted":true},"outputs":[{"name":"stdout","text":"R√©sultat: {'ordre': 'Lepidoptera', 'famille': 'Erebidae', 'genre': 'Arctia', 'espece': 'virginalis'}\nImage valide\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from utils import tree\n\n# total = tree(''/kaggle/input/inaturalist-insects/'', 2)                   # Tr√®s long temps d'attente (30min-1h)\ntotal = tree('/kaggle/input/inaturalist-insects/val-json/', 2)\nprint(f\"\\nNombre total de fichiers : {total}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-24T16:35:32.662386Z","iopub.execute_input":"2026-01-24T16:35:32.663288Z","iopub.status.idle":"2026-01-24T16:35:32.673645Z","shell.execute_reply.started":"2026-01-24T16:35:32.66325Z","shell.execute_reply":"2026-01-24T16:35:32.672951Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nNombre total de fichiers : 1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import ijson\n\ndef load_annotated_images(json_path):\n    \"\"\"Charge lat/lon par file_name depuis train_mini_json ou train_json.\"\"\"\n    annotated = {}\n    with open(json_path, 'rb') as f:\n        parser = ijson.items(f, 'images.item')\n        for img in parser:\n            filename = img.get('file_name', '')\n            lat = float(img.get('latitude')) if img.get('latitude') is not None else 0.0\n            lon = float(img.get('longitude')) if img.get('longitude') is not None else 0.0\n            annotated[filename] = (lat, lon)\n    return annotated","metadata":{"execution":{"iopub.status.busy":"2026-01-28T19:31:59.145398Z","iopub.execute_input":"2026-01-28T19:31:59.14575Z","iopub.status.idle":"2026-01-28T19:31:59.151961Z","shell.execute_reply.started":"2026-01-28T19:31:59.145723Z","shell.execute_reply":"2026-01-28T19:31:59.151146Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from collections import Counter\n\ndef compute_stats(full_taxa_map, full_geo_db, species_encountered):\n    \"\"\"Calcule toutes stats.\"\"\"\n    ordre_count = Counter()\n    famille_count = Counter()\n    genre_count = Counter()\n    espece_count = Counter()\n    \n    for taxon_key, hier in full_taxa_map.items():\n        ordre_count[hier['ordre']] += 1\n        famille_count[hier['famille']] += 1\n        genre_count[hier['genre']] += 1\n        espece_count[hier['espece']] += 1\n    \n    homonyms_count = len([s for s in species_encountered if len(species_encountered[s]) > 1])\n    homonyms_dirs = sum(len(species_encountered[s]) for s in species_encountered if len(species_encountered[s]) > 1)\n    \n    taxon_geo_counts = {str(k): len(v) for k, v in full_geo_db.items()}\n    geo_taxa = len(full_geo_db)\n    total_taxa = len(full_taxa_map)\n    multi_geo = sum(1 for c in taxon_geo_counts.values() if c > 1)\n    \n    return {\n        'total_dirs': len(species_encountered),\n        'unique_taxa': total_taxa,\n        'geo_coverage': geo_taxa / total_taxa if total_taxa else 0,\n        'homonyms': {'names': homonyms_count, 'dirs': homonyms_dirs},\n        'hierarchy': {\n            'ordres': len(ordre_count), 'familles': len(famille_count), 'genres': len(genre_count)\n        },\n        'taxon_geo_counts': taxon_geo_counts\n    }, ordre_count, famille_count, genre_count","metadata":{"execution":{"iopub.status.busy":"2026-01-28T19:32:01.721214Z","iopub.execute_input":"2026-01-28T19:32:01.721627Z","iopub.status.idle":"2026-01-28T19:32:01.913004Z","shell.execute_reply.started":"2026-01-28T19:32:01.721602Z","shell.execute_reply":"2026-01-28T19:32:01.91221Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from utils import parse_taxonomy_folders, build_taxa_maps\n\nannotated_images = load_annotated_images('/kaggle/input/inaturalist-insects/train-json/train.json')\nspecies_encountered, unparsed_dirs = parse_taxonomy_folders('/kaggle/input/inaturalist-insects/train/train/')\nfull_taxa_map, full_geo_db = build_taxa_maps(species_encountered, annotated_images, '/kaggle/input/inaturalist-insects/train/train/')\nstats, ordre_count, famille_count, genre_count = compute_stats(full_taxa_map, full_geo_db, species_encountered)\n\nprint(f\"‚úÖ {stats['unique_taxa']} taxons (sur {stats['total_dirs']} dossiers)\")\nprint(f\"Homonymes: {stats['homonyms']['names']} noms => {stats['homonyms']['dirs']} dossiers\")\nprint(f\"Hi√©rarchie: {stats['hierarchy']['ordres']} ordres, {stats['hierarchy']['familles']} familles, {stats['hierarchy']['genres']} genres\")\nprint(f\"G√©o: {len(full_geo_db)}/{len(full_taxa_map)} ({stats['geo_coverage']*100:.1f}%)\")\nprint(f\"Non pars√©s: {len(unparsed_dirs)}\")\n\n\nsave_hierarchy_map(full_taxa_map, full_geo_db, stats, 'hierarchy_map.json')","metadata":{"execution":{"iopub.status.busy":"2026-01-28T19:32:03.797753Z","iopub.execute_input":"2026-01-28T19:32:03.798317Z","iopub.status.idle":"2026-01-28T19:34:25.258303Z","shell.execute_reply.started":"2026-01-28T19:32:03.79829Z","shell.execute_reply":"2026-01-28T19:34:25.257335Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ 2526 taxons (sur 2252 dossiers)\nHomonymes: 185 noms => 459 dossiers\nHi√©rarchie: 17 ordres, 190 familles, 1472 genres\nG√©o: 0/2526 (0.0%)\nNon pars√©s: 0\nüíæ Sauvegard√©: 2526 taxons dans hierarchy_map.json\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from utils import build_hierarchy_labels\n\ndata_dir = '/kaggle/input/inaturalist-insects/'\nhierarchy_map_file = '/kaggle/working/hierarchy_map.json'\nfinal_hierarchy = build_hierarchy_labels(data_dir, hierarchy_map_file)\n\nprint(\"\\nExemples:\")\nfor idx in range(5):\n    labels = final_hierarchy.get(idx)\n    print(f\"Class {idx}: {labels}\") # [ordre_id, famille_id, genre_id, espece_id]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T08:20:49.530903Z","iopub.execute_input":"2026-02-12T08:20:49.531264Z","iopub.status.idle":"2026-02-12T08:20:52.13714Z","shell.execute_reply.started":"2026-02-12T08:20:49.531233Z","shell.execute_reply":"2026-02-12T08:20:52.136136Z"}},"outputs":[{"name":"stdout","text":"Classes: 2526 (scan /kaggle/input/inaturalist-insects/train_mini/train_mini)\nHi√©rarchie: 17 ordres, 190 fam., 1472 genres\n‚úÖ 2526/2526 mapp√©es\nüíæ hierarchy_labels.json pr√™t pour training\n\nExemples:\nClass 0: [0, 21, 124, 0]\nClass 1: [0, 21, 1048, 1]\nClass 2: [0, 21, 1219, 2]\nClass 3: [0, 23, 185, 3]\nClass 4: [0, 23, 1090, 4]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class RobustImageFolder(Dataset):\n    \"\"\"ImageFolder skip corrompus.\"\"\"\n    def __init__(self, root, transform=None, corrupt_files=None):\n        self.root = root\n        self.transform = transform\n        self.corrupt_files = set(corrupt_files or [])\n        \n        self.classes, self.class_to_idx = self.find_classes(self.root)\n        self.samples = self.make_dataset(self.root, self.class_to_idx)\n        \n        self.valid_indices = []\n        for i, (path, _) in enumerate(self.samples):\n            if os.path.relpath(path, self.root) not in self.corrupt_files:\n                self.valid_indices.append(i)\n    \n    def find_classes(self, directory):\n        \"\"\"Trouve classes (dossiers).\"\"\"\n        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n        return classes, class_to_idx\n    \n    def make_dataset(self, directory, class_to_idx):\n        \"\"\"Construit samples comme ImageFolder.\"\"\"\n        samples = []\n        for target_class in sorted(self.class_to_idx.keys()):\n            class_index = self.class_to_idx[target_class]\n            target_dir = os.path.join(directory, target_class)\n            for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root, fname)\n                    item = (path, class_index)\n                    samples.append(item)\n        return samples\n    \n    def __getitem__(self, index):\n        path, target = self.samples[self.valid_indices[index]]\n        img = Image.open(path).convert(\"RGB\")\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n    \n    def __len__(self):\n        return len(self.valid_indices)","metadata":{"execution":{"iopub.status.busy":"2026-02-12T08:21:01.309181Z","iopub.execute_input":"2026-02-12T08:21:01.309543Z","iopub.status.idle":"2026-02-12T08:21:01.321372Z","shell.execute_reply.started":"2026-02-12T08:21:01.309514Z","shell.execute_reply":"2026-02-12T08:21:01.320436Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from utils import scan_corrupted_images\n\ncorrupted_train, train_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/train/train', max_workers=4)\ncorrupted_val, val_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/val/val', max_workers=4)\ncorrupted_train_mini, train_mini_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/train_mini/train_mini', max_workers=4)\ncorrupted_test, test_log = scan_corrupted_images('/kaggle/input/inaturalist-insects/public_test/public_test', max_workers=4)\n\nwith open(train_log) as f:\n    print(\"\\nCORROMPUS TRAIN:\\n\", f.read())","metadata":{"execution":{"iopub.status.busy":"2026-02-12T08:22:54.282149Z","iopub.execute_input":"2026-02-12T08:22:54.282477Z","iopub.status.idle":"2026-02-12T09:57:35.972565Z","shell.execute_reply.started":"2026-02-12T08:22:54.282449Z","shell.execute_reply":"2026-02-12T09:57:35.967614Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Scan 663682 JPG dans /kaggle/input/inaturalist-insects/train/train\n\nTYPES D'ERREURS:\n‚úÖ 0/663682 (0.0%) en 2424.3s\nScan 25260 JPG dans /kaggle/input/inaturalist-insects/val/val\n\nTYPES D'ERREURS:\n‚úÖ 0/25260 (0.0%) en 100.1s\nScan 126300 JPG dans /kaggle/input/inaturalist-insects/train_mini/train_mini\n‚ùå 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: OSError: image file is truncated (115 bytes not processed)\n‚ùå 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: OSError: image file is truncated (43 bytes not processed)\n‚ùå 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural\n‚ùå 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural\n‚ùå 01493_Animalia_Arthropoda_Insecta_Lepidoptera_Lyca: OSError: image file is truncated (124 bytes not processed)\n‚ùå 00620_Animalia_Arthropoda_Insecta_Hemiptera_Pentat: OSError: image file is truncated (62 bytes not processed)\n‚ùå 00620_Animalia_Arthropoda_Insecta_Hemiptera_Pentat: UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural\n‚ùå 00620_Animalia_Arthropoda_Insecta_Hemiptera_Pentat: OSError: image file is truncated (67 bytes not processed)\n‚ùå 00620_Animalia_Arthropoda_Insecta_Hemiptera_Pentat: OSError: image file is truncated (88 bytes not processed)\n\nTYPES D'ERREURS:\n  UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural: 45\n  OSError: image file is truncated (115 bytes not processed): 1\n  OSError: image file is truncated (43 bytes not processed): 1\n  OSError: image file is truncated (124 bytes not processed): 1\n  OSError: image file is truncated (62 bytes not processed): 1\n  OSError: image file is truncated (67 bytes not processed): 1\n  OSError: image file is truncated (88 bytes not processed): 1\n  OSError: image file is truncated (23 bytes not processed): 1\n  OSError: image file is truncated (26 bytes not processed): 1\n  OSError: image file is truncated (83 bytes not processed): 1\n  OSError: image file is truncated (106 bytes not processed): 1\n‚úÖ 55/126300 (0.0%) en 451.6s\nScan 500000 JPG dans /kaggle/input/inaturalist-insects/public_test/public_test\n‚ùå 85770.jpg: UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural\n‚ùå 45344.jpg: UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural\n\nTYPES D'ERREURS:\n  UnidentifiedImageError: cannot identify image file '/kaggle/input/inatural: 2\n‚úÖ 2/500000 (0.0%) en 2701.7s\n\nCORROMPUS TRAIN:\n # Corrompus: 0/663682 (0.0%)\n# Erreurs:\n\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"corrupt_train = []\nwith open('/kaggle/working/corrupted_train.txt') as f:\n    for line in f:\n        if line.strip() and not line.startswith('#'):\n            corrupt_train.append(line.strip())\n\ncorrupt_val = []\nwith open('/kaggle/working/corrupted_val.txt') as f:\n    for line in f:\n        if line.strip() and not line.startswith('#'):\n            corrupt_val.append(line.strip())","metadata":{"execution":{"iopub.status.busy":"2026-02-09T10:02:49.433346Z","iopub.execute_input":"2026-02-09T10:02:49.433646Z","iopub.status.idle":"2026-02-09T10:02:49.438999Z","shell.execute_reply.started":"2026-02-09T10:02:49.433608Z","shell.execute_reply":"2026-02-09T10:02:49.438334Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class HierarchicalInsectDataset(Dataset):\n    def __init__(self, root_dir, hierarchy_map, transform=None, corrupt_files=None):\n        self.root_dir = root_dir\n        self.hierarchy_map = hierarchy_map\n        self.transform = transform\n        \n        self.inner_dataset = datasets.ImageFolder(root_dir)\n        \n        self.valid_indices = []\n        for i in range(len(self.inner_dataset)):\n            class_idx = self.inner_dataset.targets[i]\n            if class_idx in self.hierarchy_map:\n                # Skip si basename dans corrupt_files\n                path = self.inner_dataset.samples[i][0]\n                if os.path.basename(path) not in (corrupt_files or []):\n                    self.valid_indices.append(i)\n        \n        print(f\"Dataset {root_dir}: {len(self.inner_dataset)} ‚Üí {len(self.valid_indices)} valides\")\n    \n    def __getitem__(self, idx):\n        real_idx = self.valid_indices[idx]\n        img, class_idx = self.inner_dataset[real_idx]\n        \n        # Labels hi√©rarchiques [ordre_id, famille_id, genre_id, espece_id]\n        hier_labels = torch.tensor(self.hierarchy_map[class_idx])\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        return img, hier_labels\n    \n    def __len__(self):\n        return len(self.valid_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T10:02:54.416472Z","iopub.execute_input":"2026-02-09T10:02:54.41724Z","iopub.status.idle":"2026-02-09T10:02:54.423307Z","shell.execute_reply.started":"2026-02-09T10:02:54.41721Z","shell.execute_reply":"2026-02-09T10:02:54.422672Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\n\ntrain_transforms = transforms.Compose([\n    transforms.RandomRotation(30),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.3),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_dataset = HierarchicalInsectDataset(\n    '/kaggle/input/inaturalist-insects/train/train', \n    final_hierarchy, \n    transform=train_transforms,\n    corrupt_files=[os.path.basename(p) for p in corrupt_train]\n)\n\nval_dataset = HierarchicalInsectDataset(\n    '/kaggle/input/inaturalist-insects/val/val', \n    final_hierarchy, \n    transform=val_transforms,\n    corrupt_files=[os.path.basename(p) for p in corrupt_val]\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"‚úÖ Datasets hi√©rarchiques:\")\nprint(f\"  Train: {len(train_dataset)} images, 2526 classes\")\nprint(f\"  Val: {len(val_dataset)} images\")\nprint(f\"  Labels: ordre/famille/genre/espece [device={device}]\")\n\nimg, labels = next(iter(train_loader))\nprint(f\"Batch shape: {img.shape}, labels shape: {labels.shape}\")  # [32,3,224,224], [32,4]","metadata":{"execution":{"iopub.status.busy":"2026-02-09T10:02:56.559398Z","iopub.execute_input":"2026-02-09T10:02:56.560035Z","iopub.status.idle":"2026-02-09T10:06:16.881375Z","shell.execute_reply.started":"2026-02-09T10:02:56.560006Z","shell.execute_reply":"2026-02-09T10:06:16.880552Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Dataset /kaggle/input/inaturalist-insects/train/train: 663682 ‚Üí 663682 valides\nDataset /kaggle/input/inaturalist-insects/val/val: 25260 ‚Üí 25260 valides\n‚úÖ Datasets hi√©rarchiques:\n  Train: 663682 images, 2526 classes\n  Val: 25260 images\n  Labels: ordre/famille/genre/espece [device=cuda]\nBatch shape: torch.Size([32, 3, 224, 224]), labels shape: torch.Size([32, 4])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class HierarchicalMobileNetV3(nn.Module):\n    \"\"\"MobileNetV3 avec outputs s√©par√©s par niveau.\"\"\"\n    def __init__(self, num_ordre=17, num_famille=190, num_genre=1472, num_espece=2526):\n        super().__init__()\n        backbone = models.mobilenet_v3_large(weights='IMAGENET1K_V1')\n        self.features = backbone.features\n        self.avgpool = backbone.avgpool\n        \n        self.fc_shared = nn.Sequential(\n            nn.Linear(960, 512),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.3)\n        )\n        \n        # Heads ind√©pendants (FIX: pas cumulatif)\n        self.head_ordre = nn.Linear(512, num_ordre)\n        self.head_famille = nn.Linear(512, num_famille)\n        self.head_genre = nn.Linear(512, num_genre)\n        self.head_espece = nn.Linear(512, num_espece)\n    \n    def forward(self, x, return_probs=False):\n        x = self.features(x)\n        x = self.avgpool(x)\n        feats = torch.flatten(x, 1)\n        shared = self.fc_shared(feats)\n        \n        ordre = self.head_ordre(shared)\n        famille = self.head_famille(shared)\n        genre = self.head_genre(shared)\n        espece = self.head_espece(shared)\n        \n        if return_probs:\n            return (F.softmax(ordre, dim=1), F.softmax(famille, dim=1), \n                   F.softmax(genre, dim=1), F.softmax(espece, dim=1))\n        \n        max_classes = 2526\n        preds = torch.zeros(x.size(0), 4, max_classes, device=x.device)\n        preds[:, 0, :ordre.size(1)] = ordre\n        preds[:, 1, :famille.size(1)] = famille\n        preds[:, 2, :genre.size(1)] = genre\n        preds[:, 3, :espece.size(1)] = espece\n        \n        return preds  # [B,4,2526]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T10:08:13.412874Z","iopub.execute_input":"2026-02-09T10:08:13.413611Z","iopub.status.idle":"2026-02-09T10:08:13.421908Z","shell.execute_reply.started":"2026-02-09T10:08:13.413575Z","shell.execute_reply":"2026-02-09T10:08:13.421168Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"with open('hierarchy_labels.json') as f:\n    stats = json.load(f)['stats']\n    \nnum_ordre = stats['ordres']      # 17\nnum_famille = stats['familles']  # 190\nnum_genre = stats['genres']     # 1472\nnum_espece = stats['total_classes']  # 2526","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T10:08:15.454515Z","iopub.execute_input":"2026-02-09T10:08:15.455247Z","iopub.status.idle":"2026-02-09T10:08:15.463985Z","shell.execute_reply.started":"2026-02-09T10:08:15.455218Z","shell.execute_reply":"2026-02-09T10:08:15.463065Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class HierarchicalLoss(nn.Module):\n    def __init__(self, num_classes_per_level):\n        super().__init__()\n        self.ce = nn.CrossEntropyLoss()\n        self.weights = torch.tensor([1.0, 2.0, 5.0, 10.0])\n        self.num_classes = num_classes_per_level  # [17,190,1472,2526]\n    \n    def forward(self, preds, targets):\n        loss = 0\n        for i in range(4):\n            mask = torch.arange(self.num_classes[i], device=preds.device)\n            lvl_pred = preds[:, i, mask]\n            lvl_loss = self.ce(lvl_pred, targets[:, i])\n            loss += self.weights[i] * lvl_loss\n        return loss / self.weights.sum()\n\ncriterion = HierarchicalLoss([num_ordre, num_famille, num_genre, num_espece])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T10:08:17.536511Z","iopub.execute_input":"2026-02-09T10:08:17.537197Z","iopub.status.idle":"2026-02-09T10:08:17.543097Z","shell.execute_reply.started":"2026-02-09T10:08:17.537165Z","shell.execute_reply":"2026-02-09T10:08:17.542366Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\n\nmodel = HierarchicalMobileNetV3(num_ordre, num_famille, num_genre, num_espece).to(device)\n\nprint(f\"Model: {sum(p.numel() for p in model.parameters()):,} params\")\nprint(f\"‚úÖ GPU: {next(model.parameters()).device}\")\n\nmodel.eval()\nwith torch.no_grad():\n    batch_img, batch_labels = next(iter(train_loader))\n    preds = model(batch_img.to(device))  # [32,4,2526]\n    loss = criterion(preds, batch_labels.to(device))\n    print(f\"‚úÖ Test OK: preds={preds.shape}, loss={loss.item():.3f}\")","metadata":{"execution":{"iopub.status.busy":"2026-02-09T10:08:20.741589Z","iopub.execute_input":"2026-02-09T10:08:20.741918Z","iopub.status.idle":"2026-02-09T10:08:23.234249Z","shell.execute_reply.started":"2026-02-09T10:08:20.741892Z","shell.execute_reply":"2026-02-09T10:08:23.233467Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.1M/21.1M [00:00<00:00, 181MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model: 5,622,173 params\n‚úÖ GPU: cuda:0\n‚úÖ Test OK: preds=torch.Size([32, 4, 2526]), loss=7.121\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T10:08:25.125802Z","iopub.execute_input":"2026-02-09T10:08:25.126508Z","iopub.status.idle":"2026-02-09T10:08:25.13178Z","shell.execute_reply.started":"2026-02-09T10:08:25.126469Z","shell.execute_reply":"2026-02-09T10:08:25.130995Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import os\n\nos.makedirs(\"onnx\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T09:59:12.962086Z","iopub.execute_input":"2026-02-01T09:59:12.962759Z","iopub.status.idle":"2026-02-01T09:59:12.966611Z","shell.execute_reply.started":"2026-02-01T09:59:12.96272Z","shell.execute_reply":"2026-02-01T09:59:12.965831Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torch.amp import autocast, GradScaler\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport torch.onnx\n\n\ndef setup_training(\n    model,\n    num_ordre,\n    num_famille,\n    num_genre,\n    num_espece,\n    checkpoint_path=None,\n    device=None,\n    lr=1e-4,\n    weight_decay=1e-4,\n    patience=10,\n):\n    \"\"\"\n    Pr√©pare l'entra√Ænement hi√©rarchique, avec tentative de reprise depuis un checkpoint.\n\n    - Si `checkpoint_path` existe et se charge correctement -> reprise.\n    - Sinon -> entra√Ænement √† partir de z√©ro.\n    \"\"\"\n\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    criterion = HierarchicalLoss([num_ordre, num_famille, num_genre, num_espece])\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, patience=3, factor=0.5, min_lr=1e-6\n    )\n    scaler = GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Valeurs par d√©faut (from scratch)\n    start_epoch = 0\n    best_val_acc = 0.0\n    patience_counter = 0\n\n    train_losses, val_losses, val_accs = [], [], []\n    hierarchy_accs = {\"ordre\": [], \"famille\": [], \"genre\": [], \"espece\": []}\n\n    # Tentative de reprise\n    if checkpoint_path is not None:\n        try:\n            checkpoint = torch.load(checkpoint_path, map_location=device)\n            model.load_state_dict(checkpoint['model'])\n\n            if 'optim' in checkpoint:\n                optimizer.load_state_dict(checkpoint['optim'])\n            if 'scheduler' in checkpoint:\n                scheduler.load_state_dict(checkpoint['scheduler'])\n\n            start_epoch = checkpoint.get('epoch', -1) + 1\n            best_val_acc = checkpoint.get('val_acc', 0.0)\n            stats = checkpoint.get('stats', {})\n            train_losses = stats.get('train_losses', [])\n            val_losses = stats.get('val_losses', [])\n            val_accs = stats.get('val_accs', [])\n\n            if 'hierarchy_accs' in stats:\n                for k in hierarchy_accs.keys():\n                    if k in stats['hierarchy_accs']:\n                        hierarchy_accs[k] = list(stats['hierarchy_accs'][k])\n\n            print(f\"‚úÖ Reprise depuis '{checkpoint_path}' √† l'epoch {start_epoch}, Best Acc: {best_val_acc:.4f}\")\n            print(f\"üìä History: {len(train_losses)} epochs d√©j√† faits\")\n        except FileNotFoundError:\n            print(f\"‚ö†Ô∏è Checkpoint '{checkpoint_path}' introuvable, entra√Ænement √† partir de z√©ro.\")\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Impossible de charger le checkpoint '{checkpoint_path}' ({e}), entra√Ænement √† partir de z√©ro.\")\n\n    print(\"üöÄ D√©but entra√Ænement hi√©rarchique\")\n\n    return {\n        \"model\": model,\n        \"device\": device,\n        \"criterion\": criterion,\n        \"optimizer\": optimizer,\n        \"scheduler\": scheduler,\n        \"scaler\": scaler,\n        \"start_epoch\": start_epoch,\n        \"best_val_acc\": best_val_acc,\n        \"patience\": patience,\n        \"patience_counter\": patience_counter,\n        \"train_losses\": train_losses,\n        \"val_losses\": val_losses,\n        \"val_accs\": val_accs,\n        \"hierarchy_accs\": hierarchy_accs,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T10:08:31.262348Z","iopub.execute_input":"2026-02-09T10:08:31.262974Z","iopub.status.idle":"2026-02-09T10:08:31.274036Z","shell.execute_reply.started":"2026-02-09T10:08:31.262947Z","shell.execute_reply":"2026-02-09T10:08:31.273331Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import torch\nfrom torch.amp import autocast, GradScaler\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport torch.onnx\n\nprint(f\"Labels shape: {labels.shape}, dtype: {labels.dtype}\")\nprint(f\"Sample labels[0]: {labels[0]}\")\nprint(f\"preds shape: {preds.shape}\")\n\nstate = setup_training(\n    model,\n    num_ordre, num_famille, num_genre, num_espece,\n    checkpoint_path=\"/kaggle/working/best_hier_model.pth\"\n)\n\nmodel = state[\"model\"]\ndevice = state[\"device\"]\ncriterion = state[\"criterion\"]\noptimizer = state[\"optimizer\"]\nscheduler = state[\"scheduler\"]\nscaler = state[\"scaler\"]\nstart_epoch = state[\"start_epoch\"]\nbest_val_acc = state[\"best_val_acc\"]\npatience = state[\"patience\"]\npatience_counter = state[\"patience_counter\"]\ntrain_losses = state[\"train_losses\"]\nval_losses = state[\"val_losses\"]\nval_accs = state[\"val_accs\"]\nhierarchy_accs = state[\"hierarchy_accs\"]\n\nfor epoch in range(start_epoch, 50):\n    # === TRAIN ===\n    model.train()\n    train_loss = 0\n    pbar = tqdm(train_loader, desc=f'Epoch {epoch:2d}')\n    \n    for batch_idx, (images, labels) in enumerate(pbar):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        \n        optimizer.zero_grad(set_to_none=True)\n        \n        with autocast('cuda'):\n            preds = model(images)  # [B,4,2526]\n            loss = criterion(preds, labels)\n        \n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        \n        train_loss += loss.item()\n        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n    \n    avg_train_loss = train_loss / len(train_loader)\n    \n    # === VAL ===\n    model.eval()\n    val_loss_total = 0\n    val_correct = [0,0,0,0]  # [ordre, famille, genre, esp√®ce]\n    val_total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n            preds = model(images)\n            loss = criterion(preds, labels)\n            val_loss_total += loss.item()\n        \n            for lvl in range(4):\n                logits = preds[:, lvl, :criterion.num_classes[lvl]]\n                lvl_preds = logits.argmax(1)\n                val_correct[lvl] += (lvl_preds == labels[:, lvl]).sum().item()\n        \n            val_total += labels.size(0)\n\n    avg_val_loss = val_loss_total / len(val_loader)\n    hierarchy_accs_current = {\n        'ordre': val_correct[0]/val_total,\n        'famille': val_correct[1]/val_total,\n        'genre': val_correct[2]/val_total,\n        'espece': val_correct[3]/val_total\n    }\n    val_acc = hierarchy_accs_current['espece']\n    \n    print(f\"Epoch {epoch:2d}: Train={avg_train_loss:.4f} | Val={avg_val_loss:.4f}\")\n    print(f\"  Accs - Ordre:{hierarchy_accs_current['ordre']:.4f} | Fam:{hierarchy_accs_current['famille']:.4f} | \"\n          f\"Genre:{hierarchy_accs_current['genre']:.4f} | Esp:{val_acc:.4f}\")\n    \n    # Update tracking lists\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n    val_accs.append(val_acc)\n    for k in hierarchy_accs:\n        hierarchy_accs[k].append(hierarchy_accs_current[k])\n    \n    # PLOT avec vraies accuracies\n    plt.figure(figsize=(15,4))\n    plt.subplot(1,3,1); \n    plt.plot(train_losses, 'b-', label='Train'); plt.plot(val_losses, 'r-', label='Val'); plt.legend(); plt.title('Loss')\n    plt.subplot(1,3,2); plt.plot(val_accs, 'g-'); plt.title('Val Esp√®ce Acc'); plt.ylim(0,1)\n    plt.subplot(1,3,3); \n    keys = ['Ordre','Famille','Genre','Esp√®ce']\n    accs = [hierarchy_accs_current['ordre'], hierarchy_accs_current['famille'], \n            hierarchy_accs_current['genre'], hierarchy_accs_current['espece']]\n    plt.bar(keys, accs); plt.title('Val Hierarchy Accs'); plt.ylim(0,1)\n    plt.tight_layout(); plt.show()\n    \n    # EXPORT ONNX toutes les 5 epochs\n    if (epoch + 1) % 5 == 0:\n        model.eval()\n        dummy_input = torch.randn(1, 3, 224, 224).to(device)\n        \n        # Test forward pour voir les vraies outputs\n        with torch.no_grad():\n            test_output = model(dummy_input)\n            print(f\"Model outputs shape: {test_output.shape if isinstance(test_output, torch.Tensor) else [o.shape for o in test_output]}\")\n        \n        # Export simple (1 input ‚Üí 1 output principal)\n        torch.onnx.export(\n            model, \n            dummy_input, \n            f\"onnx/insect_model_epoch_{epoch+1}.onnx\",\n            export_params=True, \n            opset_version=17,  # +r√©cent = mieux support\n            do_constant_folding=True,\n            input_names=['image'],\n            output_names=['logits'],  # 1 seul output\n            dynamic_axes={\n                'image': {0: 'batch_size'},\n                'logits': {0: 'batch_size'}\n            }\n        )\n        print(f\"üíæ ONNX exported: onnx/insect_model_epoch_{epoch+1}.onnx\")\n\n    \n    # SAVE BEST\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        patience_counter = 0\n        torch.save({\n            'model': model.state_dict(),\n            'optim': optimizer.state_dict(),\n            'epoch': epoch,\n            'val_acc': val_acc,\n            'hierarchy_accs': hierarchy_accs_current,\n            'stats': {'train_losses': train_losses.copy(), 'val_losses': val_losses.copy(), \n                     'val_accs': val_accs.copy(), 'hierarchy_accs': hierarchy_accs.copy()}\n        }, 'best_hier_model.pth')\n        print(f\"üî• BEST: Esp.Acc={val_acc:.4f}\")\n    else:\n        patience_counter += 1\n    \n    scheduler.step(avg_val_loss)\n    \n    if patience_counter >= patience:\n        print(f\"üõë Early Stop at epoch {epoch}\")\n        break\n\nprint(f\"üèÜ FINAL: Best Esp√®ce Acc = {best_val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T10:08:33.608834Z","iopub.execute_input":"2026-02-09T10:08:33.609148Z"}},"outputs":[{"name":"stdout","text":"Labels shape: torch.Size([32, 4]), dtype: torch.int64\nSample labels[0]: tensor([   7,   68, 1341,  953])\npreds shape: torch.Size([32, 4, 2526])\n‚úÖ Reprise depuis '/kaggle/working/best_hier_model.pth' √† l'epoch 13, Best Acc: 0.7730\nüìä History: 13 epochs d√©j√† faits\nüöÄ D√©but entra√Ænement hi√©rarchique\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13:  16%|‚ñà‚ñå        | 3237/20741 [15:50<1:27:38,  3.33it/s, loss=0.7563]","output_type":"stream"}],"execution_count":null}]}